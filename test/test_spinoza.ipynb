{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib notebook\n",
    "import mkl\n",
    "mkl.set_num_threads(20)\n",
    "import matplotlib\n",
    "#necessary for plotly interactivity. dont ask me why\n",
    "matplotlib.use('nbagg')\n",
    "import numpy as np\n",
    "import scipy as sp \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#from scipy import special\n",
    "from random import gauss\n",
    "#import hdf5storage\n",
    "import h5py\n",
    "import timeit\n",
    "#from numba import jit\n",
    "#from sympy.solvers.solveset import nonlinsolve\n",
    "#from sympy.core.symbol import symbols\n",
    "#from sympy import exp\n",
    "from scipy import stats, io, sparse\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from core.analysis import *\n",
    "from core.simulation import *\n",
    "import similaritymeasures as sm\n",
    "sp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct connectome (no need to rerun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#(if needed) construct some necessary properties from the 'Fibers' matlab data\n",
    "#note that the function is set to utilize the data in 'fgCC', following selen's instruction\n",
    "#however, another fiber dataset is present inside 'Fibers', called 'fg'.\n",
    "#the other dataset can be selected manually from inside the function\n",
    "construct_fibers_from_data(\n",
    "                #data from Selen Atasoy\n",
    "                filepath_data='G:/Macbook Stuff/Downloads/NeuralFieldModelv2/100307_Laplace.mat',\n",
    "                filepath_Fibers='G:/Macbook Stuff/Downloads/Fibers.mat',\n",
    "                           \n",
    "                savefiles=True,\n",
    "                bundle_size=7,\n",
    "                output_filepath_fiber_edges='G:/Macbook Stuff/Downloads/NeuralFieldModelv2/fg_fiber_bundles.npy',\n",
    "                output_filepath_fiber_lengths='G:/Macbook Stuff/Downloads/NeuralFieldModelv2/fg_fiber_lengths.npy',                       \n",
    "                output_filepath_fiber_dist_starts='G:/Macbook Stuff/Downloads/NeuralFieldModelv2/fg_fiber_dist_starts.npy',\n",
    "                output_filepath_fiber_dist_ends='G:/Macbook Stuff/Downloads/NeuralFieldModelv2/fg_fiber_dist_ends.npy',\n",
    "                output_filepath_fiber_ends='G:/Macbook Stuff/Downloads/NeuralFieldModelv2/fg_fiber_ends.npy')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#(if needed) construct the mesh + DTI adjacency directly from the 'faces' and 'fibers' datasets\n",
    "#the subcortical nodes and edges are excluded at the end of the procedure\n",
    "#if the 'visual' option is selected, the function also returns datasets in suitable format for plotly\n",
    "mesh_DTI_adjacency, Xn, Yn, Zn, iN, jN, kN,  Xe, Ye, Ze = construct_adjacency_matrix_from_data(\n",
    "                                #data from Selen Atasoy\n",
    "                                filepath_data='/home/aqil/NFModel/100307_Laplace.mat',\n",
    "                                \n",
    "                                #results of previous cell\n",
    "                                filepath_fiber_edges=['/home/aqil/NFModel/fgCCfix_fiber_edges.npy'],#'/home/aqil/NFModel/fg_fiber_edges.npy'],\n",
    "                                filepath_fiber_lengths=['/home/aqil/NFModel/fgCCfix_fiber_lengths.npy'],#'/home/aqil/NFModel/fg_fiber_lengths.npy'],\n",
    "                                filepath_fiber_ends=['/home/aqil/NFModel/fgCCfix_fiber_ends.npy'],#'/home/aqil/NFModel/fg_fiber_ends.npy'],\n",
    "                                \n",
    "                                include_subcortex=True,\n",
    "                                add_DTI=True,\n",
    "                                fiber_speed_factor=50,\n",
    "    \n",
    "                                threshold=False,\n",
    "                                max_dist=10,\n",
    "                                filepath_fiber_dist_starts=['/home/aqil/NFModel/fgCCfix_fiber_dist_starts.npy'],#'/home/aqil/NFModel/fg_fiber_dist_starts.npy'],\n",
    "                                filepath_fiber_dist_ends=['/home/aqil/NFModel/fgCCfix_fiber_dist_ends.npy'],#'/home/aqil/NFModel/fg_fiber_dist_ends.npy'],\n",
    "\n",
    "                                visual=True,\n",
    "                                plot_subcortex=True,\n",
    "                                plot_DTI_edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('/home/aqil/NFModel/100307_Laplace.mat', 'r')\n",
    "CC = np.asarray(f['CC']['restInds'], dtype=int)\n",
    "indices = np.array([elem[0] for elem in CC])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTI_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/aqil/NFModel/subcortical_indices.npy', indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#(if needed) construct graph Laplacian from mesh data and diagonalize it\n",
    "binary = False\n",
    "#this is the same procedure used for regular graphs\n",
    "AdjMatrix=mesh_DTI_adjacency.toarray()\n",
    "#convert mm^2 to m^2\n",
    "if binary:\n",
    "    AdjMatrix[AdjMatrix>0] = 1\n",
    "else:\n",
    "    #convert mm^2 to m^2\n",
    "    AdjMatrix*=1000000\n",
    "    \n",
    "Deg=np.sum(AdjMatrix, axis=0)\n",
    "Degree_Matrix=sp.sparse.diags(Deg)\n",
    "regLap = Degree_Matrix - sp.sparse.csc_matrix(AdjMatrix)\n",
    "Laplacian=-regLap.toarray()\n",
    "\n",
    "vecs=True\n",
    "\n",
    "if vecs==False:    \n",
    "    eigenvalues=np.linalg.eigvalsh(Laplacian)\n",
    "    eigenvalues[-1]=0\n",
    "    eigenvalues=eigenvalues[::-1]\n",
    "    #np.save('G:/Macbook Stuff/Downloads/NeuralFieldModelv2/eigvals_DTI_full_200short.npy', eigenvalues)\n",
    "else:\n",
    "    eigenvalues,eigenvectors=np.linalg.eigh(Laplacian)\n",
    "    #eigenvalues[-1]=0\n",
    "    #note that the eigenvectors come out 2-normalized\n",
    "    eigenvalues=eigenvalues[::-1]\n",
    "    eigenvectors=eigenvectors[:,::-1]\n",
    "    np.save('/home/aqil/NFModel/eigvals_DTI_fgCCfix_subcortex_dti50.npy', eigenvalues)\n",
    "    np.save('/home/aqil/NFModel/eigvecs_DTI_fgCCfix_subcortex_dti50.npy', eigenvectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load previously constructed connectome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#len(np.nonzero(mesh_DTI_adjacency.toarray())[0])/2\n",
    "#np.shape(mesh_DTI_adjacency.toarray())\n",
    "f = h5py.File('/home/aqil/NFModel/100307_Laplace.mat', 'r')\n",
    "CC = np.asarray(f['CC']['restInds'], dtype=int)\n",
    "indices = np.array([elem[0] for elem in CC])-1\n",
    "AllVet=np.asarray(f['vertices']['all'])\n",
    "\n",
    "#u_0=np.heaviside(AllVet[0,indices],0)\n",
    "f.close()\n",
    "#no_sub=mesh_DTI_adjacency[indices,:]\n",
    "#no_sub=no_sub[:,indices]\n",
    "#len(np.nonzero(no_sub.toarray())[0])/2\n",
    "#mesh_DTI_adjacency=np.load('G:/Macbook Stuff/Downloads/NeuralFieldModelv2/metric_cortical_DTI_bundles_full_all_fibers.npy')\n",
    "#mesh_DTI_adjacency=mesh_DTI_adjacency[indices,:]\n",
    "#mesh_DTI_adjacency=mesh_DTI_adjacency[:,indices]\n",
    "#mesh_DTI_adjacency.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##np.save('G:/Macbook Stuff/Downloads/NeuralFieldModelv2/metric_cortical_DTI_bundles_full_all_fibers.npy', mesh_DTI_adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18715"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alternatively, if previously known, read eigenvalues and eigenvectors from file\n",
    "#this is what i used for the thesis. note that it has to be loaded with a minus sign\n",
    "#eigenvalues_thesis = -np.load('E:/My Documents/Dropbox/Amsterdam Math/Rikkert Hindriks/Graph-Stochastic-Wilson-Cowan-Model/data/eigvals.npy')\n",
    "#this should be the corresponding eigenvectors. they appear to be 1-normalized\n",
    "#eigenvectors_thesis = -np.load('G:/Macbook Stuff/Downloads/NeuralFieldModelv2/eigvecs.npy')\n",
    "\n",
    "#eigenvalues = np.load('G:/Macbook Stuff/Downloads/NeuralFieldModelv2/eigvals_DTI_fgCC_200short.npy')\n",
    "\n",
    "#paper\n",
    "eigenvalues = np.load('/home/aqil/NFModel/eigvals_DTI_fgCCfix_200short_metres.npy')\n",
    "eigenvectors = np.load('/home/aqil/NFModel/eigvecs_DTI_fgCCfix_200short_metres.npy')\n",
    "\n",
    "#these are all in metres unless otherwise specified\n",
    "# eigenvalues = np.load('/home/aqil/NFModel/eigvals_DTI_fgCCfix_fg_subcortex.npy')\n",
    "# eigenvectors = np.load('/home/aqil/NFModel/eigvecs_DTI_fgCCfix_fg_subcortex.npy')\n",
    "\n",
    "# eigenvalues = np.load('/home/aqil/NFModel/eigvals_DTI_fgCCfix_fg_subcortex_dti50.npy')\n",
    "# eigenvectors = np.load('/home/aqil/NFModel/eigvecs_DTI_fgCCfix_fg_subcortex_dti50.npy')\n",
    "\n",
    "#eigenvalues = np.load('/home/aqil/NFModel/eigvals_DTI_fgCCfix_fg_subcortex_dti1.npy')\n",
    "#eigenvectors = np.load('/home/aqil/NFModel/eigvecs_DTI_fgCCfix_fg_subcortex_dti1.npy')\n",
    "\n",
    "#unused\n",
    "# eigenvalues = np.load('/home/aqil/NFModel/eigvals_DTI_fgCCfix_subcortex_dti1_mm.npy')\n",
    "# eigenvectors = np.load('/home/aqil/NFModel/eigvecs_DTI_fgCCfix_subcortex_dti1_mm.npy')\n",
    "\n",
    "#eigenvalues = np.load('/home/aqil/NFModel/eigvals_DTI_fgCCfix_subcortex_dti10.npy')\n",
    "#eigenvectors = np.load('/home/aqil/NFModel/eigvecs_DTI_fgCCfix_subcortex_dti10.npy')\n",
    "\n",
    "#best so far\n",
    "#eigenvalues = np.load('/home/aqil/NFModel/eigvals_DTI_fgCCfix_subcortex_dti50.npy')\n",
    "#eigenvectors = np.load('/home/aqil/NFModel/eigvecs_DTI_fgCCfix_subcortex_dti50.npy')\n",
    "\n",
    "#eigenvalues = -np.load('E:/My Documents/Dropbox/Amsterdam Math/Rikkert Hindriks/Graph-Stochastic-Wilson-Cowan-Model/data/eigvals.npy')\n",
    "len(eigenvalues)\n",
    "#np.save('G:/Macbook Stuff/Downloads/NeuralFieldModelv2/eigvals_DTI_fgCC_200short_metres.npy', eigenvalues)\n",
    "#print(eigenvalues)\n",
    "#print(eigenvalues2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set parameters and bounds for minimization algorithms\n",
    "Graph_Kernel='Damped Wave'\n",
    "\n",
    "aEE, bnds_aEE = 140, (0,1e3)\n",
    "aIE, bnds_aIE = 155, (0,1e3)\n",
    "aEI, bnds_aEI = 165, (0,1e3)\n",
    "aII, bnds_aII = 140, (0,1e3)\n",
    "dE, bnds_dE = 2, (0,1e3)\n",
    "dI, bnds_dI = 2, (0,1e3)\n",
    "P, bnds_P = 0, (-1e3,1e3)\n",
    "Q, bnds_Q = 0, (-1e3,1e3)\n",
    "sEE, bnds_sEE = 6, (0,1e3)\n",
    "sIE, bnds_sIE = 10, (0,1e3)\n",
    "sEI, bnds_sEI = 10, (0,1e3)\n",
    "sII, bnds_sII = 50, (0,1e3)\n",
    "#D, bnds_D = 1, (0.1,10)             #unchanged\n",
    "tE, bnds_tE = 1, (0,1e3)          \n",
    "tI, bnds_tI = 1, (0,1e3)          \n",
    "#snE, bnds_snE = 1, (1,10)        #unchanged\n",
    "#snI, bnds_snI = 1, (1,10)         #unchanged\n",
    "\n",
    "initial_guess=[aEE,aIE,aEI,aII,dE,dI,P,Q,sEE,sIE,sEI,sII,tE,tI]#,snE])#,snI]) \n",
    "bnds=[bnds_aEE,bnds_aIE,bnds_aEI,bnds_aII,bnds_dE,bnds_dI,bnds_P,bnds_Q,bnds_sEE,bnds_sIE,bnds_sEI,bnds_sII,bnds_tE,bnds_tI]#,bnds_snE]#,bnds_snI]\n",
    "\n",
    "\n",
    "if Graph_Kernel == 'Damped Wave':\n",
    "    aDW_EE, bnds_aDW_EE = 0, (0,1e3)\n",
    "    aDW_IE, bnds_aDW_IE = 0, (0,1e3)\n",
    "    aDW_EI, bnds_aDW_EI = 0, (0,1e3)\n",
    "    aDW_II, bnds_aDW_II = 0, (0,1e3)\n",
    "    bDW_EE, bnds_bDW_EE = 0, (0,1e3)\n",
    "    bDW_IE, bnds_bDW_IE = 0, (0,1e3)\n",
    "    bDW_EI, bnds_bDW_EI = 0, (0,1e3)\n",
    "    bDW_II, bnds_bDW_II = 0, (0,1e3)\n",
    "    initial_guess += [aDW_EE,aDW_IE,aDW_EI,aDW_II,bDW_EE,bDW_IE,bDW_EI,bDW_II]\n",
    "    bnds += [bnds_aDW_EE,bnds_aDW_IE,bnds_aDW_EI,bnds_aDW_II,bnds_bDW_EE,bnds_bDW_IE,bnds_bDW_EI,bnds_bDW_II]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#thesis values\n",
    "first_k=2\n",
    "last_k=5000\n",
    "thesis_spatial_spectrum = 15*(np.arange(first_k,last_k)**(-0.3))\n",
    "\n",
    "#post-thesis work\n",
    "first_k=3\n",
    "last_k=len(eigenvalues)\n",
    "x_t = np.log(np.arange(first_k,last_k))\n",
    "new_spatial_spectrum = 10**(-0.012*x_t**(2.2) + 0.6 + 0.5*x_t**(-0.3))#0.02*x_t**(1.1)+1.1)# + x_t**(-1.5)+10)\n",
    "#more similar to fluctuations power data from selen\n",
    "new_spatial_spectrum = 10**(-0.018*x_t**(2.2) + 0.5 + 0.5*x_t**(-0.3))\n",
    "\n",
    "#empirical SPS\n",
    "first_k=1\n",
    "last_k=10000#len(eigenvalues)\n",
    "f = sp.io.loadmat('/home/aqil/NFModel/100307_REST1_LR_selenyeo10k.mat')\n",
    "\n",
    "if len(eigenvalues)==18715:\n",
    "    timecourse = np.nan_to_num(np.concatenate((f['selenyeo10kts_lh'],f['selenyeo10kts_rh']), axis=0)[indices])\n",
    "else:\n",
    "    timecourse = np.nan_to_num(np.concatenate((f['selenyeo10kts_lh'],f['selenyeo10kts_rh']), axis=0))\n",
    "#errors = np.nan_to_num(np.concatenate((f['selenyeo10kts_lh_stderr'],f['selenyeo10kts_rh_stderr']), axis=0)[indices])\n",
    "\n",
    "#the Laplace coefficient of the zero-mean timecourses\n",
    "coeffs = np.dot(eigenvectors.T,(timecourse-timecourse.mean(1)[...,np.newaxis]))\n",
    "#the Laplace coefficient of the z-scored timecourses\n",
    "#coeffs_zscore = np.dot(eigenvectors.T,np.nan_to_num(sp.stats.zscore(timecourse, axis=1)))\n",
    "\n",
    "#here i define logspace binning\n",
    "bins = np.unique(np.logspace(np.log10(first_k), np.log10(last_k), num=300, dtype=int))[:-1]\n",
    "bins_positions = np.array([elem.mean() for elem in np.array_split(np.arange(first_k,last_k), bins)])\n",
    "def median_binning(data,bins):\n",
    "    return np.array([np.median(elem) for elem in np.array_split(data, bins)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from matplotlib import cm\n",
    "#colors = cm.get_cmap('RdBu')(np.linspace(0,1,220))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# for c,i in enumerate(np.arange(0,1100,5)):\n",
    "    \n",
    "#     empirical_SPS=(np.abs(coeffs[:,i:(i+60)])**2).mean(1)[first_k:last_k]\n",
    "#     bins = np.unique(np.logspace(np.log10(first_k), np.log10(last_k), num=300, dtype=int))[:-1]\n",
    "#     binned_SPS = np.array([np.median(elem) for elem in np.array_split(empirical_SPS, bins)])\n",
    "#     binned_SPS_points = np.array([elem.mean() for elem in np.array_split(np.arange(first_k,last_k), bins)])\n",
    "\n",
    "#     plt.loglog(binned_SPS_points,binned_SPS,c=colors[c],alpha=0.5,lw=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aqil/.conda/envs/py310/lib/python3.10/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/aqil/.conda/envs/py310/lib/python3.10/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#empirical_SPS_errors = np.abs(np.dot(eigenvectors.T,errors)).mean(1)\n",
    "empirical_SPS=(np.abs(coeffs)**2).mean(1)[first_k:last_k]\n",
    "#keep the [:-1] to avoid empty slice problems\n",
    "bins = np.unique(np.logspace(np.log10(first_k), np.log10(last_k), num=300, dtype=int))[:-1]\n",
    "binned_SPS = np.array([np.median(elem) for elem in np.array_split(empirical_SPS, bins)])\n",
    "binned_SPS_points = np.array([elem.mean() for elem in np.array_split(np.arange(first_k,last_k), bins)])\n",
    "binned_SPS_err = np.array([sp.stats.sem(elem) for elem in np.array_split(empirical_SPS, bins)])\n",
    "len(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0df5781990>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.title(\"Spatial Power Spectrum  $P(k)$\")\n",
    "plt.xlabel(\"Spatial Eigenmode ($k$)\")\n",
    "#plt.errorbar(x=np.arange(len(empirical_SPS)), y=empirical_SPS, yerr=0, fmt='ks', markersize=1, zorder=1)\n",
    "plt.errorbar(x=binned_SPS_points, y=binned_SPS, yerr=binned_SPS_err, zorder=2, fmt='yo',markersize=3)\n",
    "\n",
    "plt.loglog(np.arange(first_k, last_k), empirical_SPS, marker='s', linestyle='', markersize=2, zorder=0, color=[0.267004, 0.004874, 0.329415, 1.])\n",
    "plot_bins = np.unique(np.logspace(0, np.log10(20000), num=300, dtype=int))[:-1]\n",
    "y_bins = np.unique(np.logspace(0, np.log10(len(eigenvalues)), num=200, dtype=int))[:-1]\n",
    "plt.hist2d(np.arange(first_k, last_k), empirical_SPS, (plot_bins, y_bins), cmap='viridis',zorder=1,cmin=2)\n",
    "\n",
    "fit_to_median=True\n",
    "if fit_to_median:\n",
    "    True_Spatial_Spectrum = binned_SPS\n",
    "    Bins=bins\n",
    "else:\n",
    "    True_Spatial_Spectrum = empirical_SPS\n",
    "    Bins=None\n",
    "        \n",
    "LSA=True\n",
    "Visual=False\n",
    "SaveFiles=False\n",
    "FilePath=' '\n",
    "\n",
    "Min_omega=5*(2*np.pi)\n",
    "Max_omega=50*(2*np.pi)\n",
    "Delta_omega=0.1*(2*np.pi)\n",
    "\n",
    "freqs=np.arange(Min_omega,Max_omega,Delta_omega)/(2*np.pi)\n",
    "\n",
    "#higher gaussian TPS\n",
    "higher_gaussian_TPS=100000/(100*freqs+10000)+5*np.exp((-(freqs-10)**2)/(2*0.9**2))\n",
    "#lower gaussian TPS\n",
    "lower_gaussian_TPS=100000/(100*freqs+10000)+3*np.exp((-(freqs-10)**2)/(2*1.2**2)) #too complex: 10*(1/(0.1*freqs+0.4)+0.7*np.exp((-(freqs-10)**2)/(2*0.9**2))+0.3*np.exp((-(freqs-22)**2)/(2*3**2)))\n",
    "#even lower gaussian TPS\n",
    "even_lower_gaussian_TPS=100000/(100*freqs+10000)+1.5*np.exp((-(freqs-10)**2)/(2*1.8**2))\n",
    "#lowest gaussian TPS\n",
    "lowest_gaussian_TPS=100000/(100*freqs+10000)+0.5*np.exp((-(freqs-10)**2)/(2*2.5**2))\n",
    "#no gaussian TPS\n",
    "no_gaussian_TPS=100000/(100*freqs+10000)\n",
    "\n",
    "#new TPS, inspired by ketamine paper. suitable for loglog plotting, so multiplicative factor\n",
    "new_TPS=2.5*freqs**(-1.25)+1.2*np.exp((-(freqs-10)**2)/(2*0.7**2)) + 0.06*np.exp((-(freqs-20)**2)/(2*0.7**2))\n",
    "new_TPS[np.where((freqs>20) & (freqs<=40))] = 35*freqs[np.where((freqs>20) & (freqs<=40))]**(-2.17) +0.06*np.exp((-(freqs[np.where((freqs>20) & (freqs<=40))]-20)**2)/(2*0.7**2))\n",
    "new_TPS[np.where(freqs>40)] = 1.17*freqs[np.where(freqs>40)]**(-1.25)\n",
    "\n",
    "#empirical TPS from Rikkert MEG data\n",
    "MEG_PS_data = sp.io.loadmat('/home/aqil/NFModel/MEG_powerspectrum.mat')\n",
    "freqs = MEG_PS_data['f'][1:][:,0]\n",
    "empirical_TPS = MEG_PS_data['p'].T[1:][:,0] * 10 **30#28\n",
    "Min_omega=1*(2*np.pi)\n",
    "Max_omega=40*(2*np.pi)\n",
    "Delta_omega=0.5*(2*np.pi)\n",
    "True_Temporal_Spectrum=np.array(empirical_TPS, dtype='float')#[int(len(new_TPS)*0.1):int(len(new_TPS)*0.5)]\n",
    "#Max_omega=25*(2*np.pi)\n",
    "\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax = fig2.add_subplot(111)\n",
    "ax.set_title(\"Temporal Power Spectrum \")\n",
    "ax.set_xlabel(\"Frequency (hz)\")\n",
    "ax.loglog(freqs, True_Temporal_Spectrum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ############################\n",
    "# #single analysis for easy visualization (note that if there are multiple stedy states the visualization will refer to the best one)\n",
    "# # better_result=dict(x=np.array([1.15357519e+02, 1.80816514e+02, 1.89765888e+02, 2.10306805e+02,\n",
    "# #        1.43682388e+01, 1.09130331e+00, 5.36635639e+00, 5.31252166e+00,\n",
    "# #        8.37626732e+00, 2.74681544e+00, 3.66503548e-02, 1.00910684e+02,\n",
    "# #        4.95497870e+00, 4.47579295e+00]))\n",
    "# plt.close('all')\n",
    "# aEE=115\n",
    "# aIE=175\n",
    "# aEI=190 \n",
    "# aII=210\n",
    "# dE=2.5 \n",
    "# dI=1 \n",
    "# P=0 \n",
    "# Q=0 \n",
    "# sEE=5.5 \n",
    "# sIE=3\n",
    "# sEI=3.5 \n",
    "# sII=100 \n",
    "# tE=1.2\n",
    "# tI=0.8\n",
    "# initial_guess=np.array([aEE,aIE,aEI,aII,dE,dI,P,Q,sEE,sIE,sEI,sII,tE,tI])\n",
    "#Ess = 0.003813#steady_states[0,nrSS]\n",
    "#Iss = 0.0522#steady_states[1,nrSS]    \n",
    "# Best suitable steady state: 0, with Ess=0.003813 Iss=0.0522.                       \n",
    "# Dist spatial: 1493, scale params: [6170.0315 1328.5838 4896.9869]                        \n",
    "# Dist temporal: 2092, scale params: [  10.7089   -3.767  -318.5677]\n",
    "Args = (eigenvalues, Graph_Kernel, True_Temporal_Spectrum, Min_omega, Max_omega, Delta_omega,\n",
    "        True_Spatial_Spectrum, first_k, last_k, Bins, LSA, Visual, SaveFiles, FilePath, 4000, True)\n",
    "# better_result=dict(x=np.array([2.0702e+02, 1.8976e+02, 5.6196e+01, 8.5851e+01, 8.8671e+00,\n",
    "#        4.3626e-01, 1.0159e+01, 2.7925e+00, 1.8276e-03, 7.9284e-03,\n",
    "#        9.9997e-03, 9.9985e-03, 1.2810e-02, 2.0920e-01, 8.4403e-07,\n",
    "#        3.6035e+02, 3.0775e+02, 3.0104e-03, 1.2251e-06, 1.6150e+02,\n",
    "#        7.2362e+02, 5.0261e-03]))\n",
    "Full_Analysis(better_result['x'], *Args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#simple attempt at power spectrum fitting with a minimization algorithm. May get stuck in local minima.\n",
    "#playing around with tolerance and max number of iterations is often necessary, depending on initial conditions. e.g.\n",
    "#First run with fairly random initial guess: tol=1e-03, no maxiter (will take a while)\n",
    "#Run starting from a previously obtained result: tol=1e-08, 'maxiter':2000\n",
    "#thesis values\n",
    "result=dict(x=np.array([1.15357519e+02, 1.80816514e+02, 1.89765888e+02, 2.10306805e+02,\n",
    "       1.43682388e+01, 1.09130331e+00, 5.36635639e+00, 5.31252166e+00,\n",
    "       1e3*8.37626732e+00, 1e3*2.74681544e+00, 1e3*3.66503548e-02, 1e3*1.00910684e+02,\n",
    "       4.95497870e+00, 4.47579295e+00]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result=dict(x=np.array([6.88112381e+02, 7.85722370e+01, 9.97105458e+02, 1.22114834e+02,\n",
    " 1.00095980e+02 ,8.71706788e+00 ,4.45444506e+00, 6.72211504e+00,\n",
    " 2.69548038e-03 ,1.94174600e-03, 1.55065050e-02, 2.22532549e-01,\n",
    " 7.02896805e-01, 2.03388273e-01]))\n",
    "result=dict(x=np.array([3.21305207e+02, 1.15229271e+02 ,2.70650624e+02, 1.50968021e+02,\n",
    " 9.72193535e+01, 2.21122739e-01, 1.40493267e+01, 6.38403082e+00,\n",
    " 2.84332179e-03, 1.20034605e-02 ,5.54375346e-02, 6.13375039e-02,\n",
    " 5.39616943e-04, 2.34386738e-05]))\n",
    "#best linear fit with intercept (also simulated)\n",
    "result=dict(x=np.array([2.68360960e+02, 1.47992427e+02, 3.40781188e+02, 1.39064758e+02,\n",
    " 3.91998061e+01 ,1.49887889e+00, 2.16422343e+01, 1.48126196e+01,\n",
    " 1.80443833e-02, 2.01119682e-03 ,7.65031385e-02 ,3.47241530e-02,\n",
    " 1.50660781e-01 ,1.30547616e+00]))\n",
    "\n",
    "result=dict(x=np.array([1.50168054e+02, 2.19398694e+02, 2.60282590e+02, 1.61754514e+02,\n",
    " 2.66754985e+01 ,1.23424895e+00, 2.22845573e+01, 8.44527415e+00,\n",
    " 1.61870040e-02, 2.01464558e-03 ,6.87269629e-02, 1.03620878e-01,\n",
    " 1.90996952e-01 ,2.41407765e-01]))\n",
    "#final\n",
    "result=dict(x=np.array([1.48665460e+02, 2.19057310e+02 ,2.62024638e+02 ,1.61437274e+02,\n",
    " 2.71802361e+01, 1.24033047e+00, 2.23516416e+01 ,8.45022796e+00,\n",
    " 1.61138979e-02, 2.02249219e-03 ,6.69814861e-02 ,9.14930664e-02,\n",
    " 2.02440304e-01, 2.34608894e-01]))\n",
    "#recent\n",
    "result=dict(x=np.array([1.48430507e+02, 2.19054822e+02, 2.62072488e+02, 1.61171273e+02,\n",
    " 2.77217907e+01, 7.11917100e-01, 2.27906562e+01, 7.66562110e+00,\n",
    " 1.37941744e-02, 2.21349125e-03, 6.95808967e-02, 1.42852777e-01,\n",
    " 3.33701978e-01, 3.79251075e-01]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import NonlinearConstraint\n",
    "\n",
    "constraints = []\n",
    "\n",
    "def spectrum_distance(x):\n",
    "    E_Spectrum, I_Spectrum = Graph_WC_Spatiotemporal_PowerSpectrum(Laplacian_eigenvalues=eigenvalues, Graph_Kernel=Graph_Kernel, Ess=SStates[0,SSnr], Iss=SStates[1,SSnr],\n",
    "                                        alpha_EE=x[0], alpha_IE=x[1], alpha_EI=x[2], alpha_II=x[3], d_e=x[4], d_i=x[5], \n",
    "                                        sigma_EE=x[8], sigma_IE=x[9], sigma_EI=x[10], sigma_II=x[11],  \n",
    "                                        D=1, tau_e=x[12], tau_i=x[13],\n",
    "                                    aDW_EE=x[14],aDW_IE=x[15], aDW_EI=x[16], aDW_II=x[17],\n",
    "                                    bDW_EE=x[18], bDW_IE=x[19], bDW_EI=x[20], bDW_II=x[21],\n",
    "                                               \n",
    "                                        sigma_noise_e=sigma_noise, sigma_noise_i=sigma_noise,\n",
    "                                        min_omega=Min_omega, max_omega=Max_omega, delta_omega=Delta_omega,\n",
    "                                        Spatial_Spectrum_Only=False, Visual=False)\n",
    "    Gw_E=2*np.sum(E_Spectrum,axis=1)\n",
    "    \n",
    "    scale_params_temporal = np.array([(True_Temporal_Spectrum.mean())/(Gw_E.mean())])\n",
    "\n",
    "    current_temporal_spectrum = NF_to_empirical(scale_params_temporal,\n",
    "                                            Gw_E, Gw_I)\n",
    "    dist_temporal = np.linalg.norm(np.log10(True_Temporal_Spectrum)-np.log10(current_temporal_spectrum), ord=2)**2\n",
    "\n",
    "    dist_temporal += np.linalg.norm((np.log10(True_Temporal_Spectrum[1:])-np.log10(True_Temporal_Spectrum[:-1]))-(np.log10(current_temporal_spectrum[1:])-np.log10(current_temporal_spectrum[:-1])), ord=2)**4\n",
    "\n",
    "    return dist_temporal\n",
    "\n",
    "constraints.append(NonlinearConstraint(spectrum_distance,\n",
    "                                                    lb=0,\n",
    "                                                    ub=1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "\n",
    "#dw manual\n",
    "# result=dict(x=np.array([6.8811e+02, 7.9165e+01, 9.9711e+02, 1.2211e+02, 1.0051e+02, 8.5666e+00,\n",
    "#  4.3092e+00, 6.9957e+00, 4.6705e-05, 1.4132e-03, 1.8037e-02, 2.3725e-01,\n",
    "#  4.2467e-01, 3.5548e-01,10**3,10**3,10**3,10**3,10,10,10,10]))\n",
    "# result=dict(x=np.array([6.88112381e+02, 7.85722370e+01, 9.97105458e+02, 1.22114834e+02,\n",
    "#  1.00095980e+02 ,8.71706788e+00 ,4.45444506e+00, 6.72211504e+00,\n",
    "#  2.69548038e-03 ,1.94174600e-03, 1.55065050e-02, 2.22532549e-01,\n",
    "#  7.02896805e-01, 2.03388273e-01,1e-8,1e-8,1e-8,1e-8,1,1,1,1]))\n",
    "# #final paper\n",
    "# result=dict(x=np.array([1.48665460e+02, 2.19057310e+02 ,2.62024638e+02 ,1.61437274e+02,\n",
    "#  2.71802361e+01, 1.24033047e+00, 2.23516416e+01 ,8.45022796e+00,\n",
    "#  1.61138979e-02, 2.02249219e-03 ,6.69814861e-02 ,9.14930664e-02,\n",
    "#  2.02440304e-01, 2.34608894e-01,1e-4,1e-4,1e-4,1e-4,1,1,1,1]))\n",
    "# result=dict(x=np.array([1.4912e+02, 2.1759e+02, 2.5921e+02, 1.6230e+02, 2.7139e+01, 1.2337e+00,\n",
    "#  2.2466e+01 ,8.1438e+00, 1.6423e-02 ,2.3137e-03, 6.6802e-02, 9.1542e-02,\n",
    "#  2.0702e-01 ,2.3107e-01, 5.5491e-07 ,2.8627e-08, 1.4574e-06, 2.2508e-06,\n",
    "#  1.0028e+00 ,1.0681e+00, 1.0393e+00 ,1.0028e+00]))\n",
    "#using correlation\n",
    "# result=dict(x=np.array([1.4868e+02, 2.1904e+02 ,2.6203e+02, 1.6145e+02, 2.7210e+01, 1.3746e+00,\n",
    "#  2.2464e+01, 8.2988e+00 ,3.8240e-01 ,1.9704e-03, 7.5561e-02 ,9.1635e-02,\n",
    "#  1.9435e-01, 1.0784e+00 ,9.9111e-01 ,9.9587e-01, 1.0038e+00 ,1.0084e+00,\n",
    "#  1.0056e-04, 2.9705e-03, 5.1942e-03 ,1.2540e-03]))\n",
    "#simplified scaling, ord2 distance, new connectome (wave params are *1e5)\n",
    "# result=dict(x=np.array([5.0412e+02, 7.8384e+01, 1.2358e+03, 1.4698e+02, 4.9484e+01, 7.1233e+00,\n",
    "#  3.9852e+00 ,3.2349e+00, 2.5905e-03, 1.9210e-03 ,2.9641e-02, 1.8067e-01,\n",
    "#  8.4580e-01, 1.8146e-01, 9.2182e-05, 1.0270e-04, 1.1615e-04, 1.3291e-04,\n",
    "#  1.1425e+00 ,1.0105e+00, 8.8928e-01, 8.1291e-01]))\n",
    "##using temp deriv\n",
    "# result=dict(x=np.array([7.1585e+02, 3.1227e+02, 2.8629e+02, 1.6478e+02, 2.6326e+01,\n",
    "#        1.2776e+00, 2.1972e+01, 9.0008e+00, 1.6353e-02, 1.9772e-03,\n",
    "#        6.8340e-02, 9.3434e-02, 1.9253e-01, 2.3090e-01, 9.7824e-01,\n",
    "#        8.6755e-01, 1.0670e+00, 9.8824e-01, 5.5653e-04, 4.4763e-06,\n",
    "#        4.4609e-07, 1.2138e-06]))\n",
    "#also spatial deriv (temp looks nice) (but spat unstable) 52/12\n",
    "# result=dict(x=np.array([7.1591e+02, 3.1259e+02, 2.8662e+02, 1.6442e+02, 2.6423e+01,\n",
    "#        1.2825e+00, 2.1835e+01, 8.7888e+00, 1.7436e-03, 1.0713e-03,\n",
    "#        7.9180e-02, 1.0382e-01, 1.9880e-01, 2.2459e-01, 9.7932e-01,\n",
    "#        8.6580e-01, 1.0692e+00, 7.9494e-01, 1.0150e-02, 1.1836e-01,\n",
    "#        5.4146e-03, 1.0648e-02]))\n",
    "#spatial deriv stable no peaks\n",
    "# result=dict(x=(np.array([2.1864e+02, 1.2605e+02, 1.8265e+02, 9.8375e+01, 3.9675e+01,\n",
    "#        6.3733e-01, 7.3077e+00, 9.4213e-01, 7.1691e-03, 4.1517e-03,\n",
    "#        8.2703e-02, 9.5257e-02, 2.2306e-01, 1.9062e-01, 3.9409e-08,\n",
    "#        3.8537e-05, 1.6828e-04, 3.0538e-04, 1.9185e+00, 9.3723e-01,\n",
    "#        1.7785e+00, 8.9270e-01])))\n",
    "#manual edits on stable no peaks attempting to get peak without destavlizing\n",
    "# result=dict(x=(np.array([2.1864e+02, 1.2605e+02, 1.8265e+02, 9.8375e+01, 3.9675e+01,\n",
    "#        6.3733e-01, 7.3077e+00, 9.4213e-01, 7.1691e-03, 4.1517e-03,\n",
    "#        8.2703e-02, 9.5257e-02, 2.2306e-01, 1.9062e-01, 9.7932e-01,\n",
    "#         8.6580e-01, 1.0692e+00, 7.9494e-01, 1.0150e-02, 1.1836e-01,\n",
    "#         5.4146e-03, 1.0648e-02])))\n",
    "##DIFF EVO\n",
    "# result=dict(x=np.array([2.18640000e+02, 1.77321423e+02, 2.97178667e+02, 9.83750000e+01,\n",
    "#        2.63635016e+01, 6.37330000e-01, 7.30770000e+00, 9.42130000e-01,\n",
    "#        3.04537982e-03, 4.15170000e-03, 1.06443266e-01, 9.52570000e-02,\n",
    "#        2.23060000e-01, 1.81494557e-01, 3.94089739e-08, 3.85370000e-05,\n",
    "#        1.22411168e+02, 3.05380000e-04, 1.91850000e+00, 2.64375950e+00,\n",
    "#        1.24421530e-06, 8.92700000e-01]))\n",
    "# #DIFF EVO 2\n",
    "# result=dict(x=np.array([2.41362341e+02, 1.87465571e+02, 3.06359129e+02, 9.83750000e+01,\n",
    "#        2.48031935e+01, 6.37329991e-01, 7.53833099e+00, 9.42130150e-01,\n",
    "#        2.29619993e-03, 4.15156353e-03, 9.20363949e-02, 1.25773356e+01,\n",
    "#        1.67598599e-01, 2.21462762e-01, 6.68549170e-07, 3.77186998e-05,\n",
    "#        3.68790813e+01, 4.29250127e+02, 1.91849997e+00, 1.53394297e-10,\n",
    "#        9.99999995e+02, 2.48366338e+01]))\n",
    "\n",
    "initial_guess=np.load('de_fitting_22_subc_dti50.npy')#better_result['x']#better_result['x']\n",
    "\n",
    "#initial_guess[14:18] *= 10\n",
    "#change none to True_Spatial_Spectrum if want to fit to both\n",
    "Args = (eigenvalues, Graph_Kernel, True_Temporal_Spectrum, Min_omega, Max_omega, Delta_omega,\n",
    "        True_Spatial_Spectrum, first_k, last_k, Bins, LSA, Visual, SaveFiles, FilePath, 20, True)\n",
    "\n",
    "\n",
    "result = sp.optimize.minimize(Full_Analysis, initial_guess, args=Args,\n",
    "                              method='Nelder-Mead', \n",
    "                              bounds=bnds,\n",
    "                              #constraints=constraints,\n",
    "                              tol=1e-6,\n",
    "                              options={#'ftol':1e-10,\n",
    "                                      # 'xtol':1e-16,\n",
    "                                     #  'maxiter': 1000,\n",
    "                                 # 'adaptive':True,\n",
    "                                   #   'maxls':200,\n",
    "                                       'disp':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(repr(result['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dwave starting from paper results (no osc)\n",
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#damped wave first manual\n",
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perfect background, no osc peaks\n",
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#500 spatial 100 temporal\n",
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no linear intercept. log norm1 **2 +area = 562.1\n",
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no linear intercept. log norm1 **2 +area = 567\n",
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no linear intercept. log norm1 **2 = 240.9 (already very good!) (+areadist =600.5)\n",
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log norm1 **2 + area =   571.9\n",
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log norm1 **2 + area =  570.9\n",
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#log norm1 **2 + area =  572.7 (TNC) (see 570 with nelme)\n",
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#log norm1 dist 13.92 (352 area)\n",
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#log norm1 dist 14.49\n",
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#area between curves in log (not loglog) space as objective function. 2norm in log space for scaling (26/01/20)\n",
    "#1336sp 39te (linear sum, interim best)\n",
    "#792.2sp 31.7te (product)(excellent for spatial, bad for temporal)\n",
    "#778sp 30te\n",
    "#289.5 areas between curv dist, 15.28 log norm1 dist \n",
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "#more complicated fitting attempt with basinhopping stochastic minimization\n",
    "#to obtain good results in sensible amounts of time, playing with minimization parameters is required\n",
    "#the relevant parameter are again tolerance and maxiter, similarly to above (which affect the local minimization loop)\n",
    "#but also niter and stepsize. these specify how many local minimizations we wish to carry out, \n",
    "#and the size of the basin-hopping random step inbetween local minimizations\n",
    "\n",
    "#best previous spectrum\n",
    "#new_initial_guess=result['x']\n",
    "\n",
    "#spectrum (thesis)\n",
    "#old_initial_guess=np.array([1.15357519e+02, 1.80816514e+02, 1.89765888e+02, 2.10306805e+02,\n",
    "#       1.43682388e+01, 1.09130331e+00, 5.36635639e+00, 5.31252166e+00,\n",
    "#       8.37626732e+00, 2.74681544e+00, 3.66503548e-02, 1.00910684e+02,\n",
    "#       4.95497870e+00, 4.47579295e+00])\n",
    "\n",
    "#new_initial_guess=np.load('first_spatiotemporal_spectrum_empirical_stps.npy', allow_pickle=True)[()]['x']\n",
    "\n",
    "#sort of ugly, but need to defind bounds manually for basinhopping\n",
    "# class MyBounds(object):\n",
    "#     def __init__(self, xmax=[elem[1] for elem in bnds], xmin=[elem[0] for elem in bnds]):#, hello=this_temporal_distance):\n",
    "#         self.xmax = np.array(xmax)\n",
    "#         self.xmin = np.array(xmin)\n",
    "#         #self.hello = hello\n",
    "#     def __call__(self, **kwargs):\n",
    "#         x = kwargs[\"x_new\"]\n",
    "#         tmax = bool(np.all(x <= self.xmax))\n",
    "#         tmin = bool(np.all(x >= self.xmin))\n",
    "#         t=tmax and tmin\n",
    "        \n",
    "#         New_Dist=Full_Analysis(x, *Args)\n",
    "        \n",
    "#         success = New_Dist<1e6\n",
    "        \n",
    "#         #if t and success and New_Dist<self.hello:\n",
    "#         #    self.hello=New_Dist\n",
    "#         #    new_initial_guess=np.copy(x)\n",
    "        \n",
    "#         return t and success\n",
    "    \n",
    "    \n",
    "    #potential TODO: only accept parameter sets that return stable positive steady states (actually no: they might be locally near a suitable state. still worth to do local minimization)\n",
    "\n",
    "#minimizer_kwargs={'args':Args, 'method':'TNC', 'bounds':bnds, 'tol':1e-03, 'options':{'maxiter':500}}\n",
    "\n",
    "\n",
    "# def custom_min(fun, x0, args, **kwargs):\n",
    "#     Bounds=bnds\n",
    "#     #Bounds[0:8]=[(elem,elem) for elem in x0[0:8]]\n",
    "     \n",
    "     \n",
    "#     result = sp.optimize.minimize(fun,x0,args=Args, method='Nelder-Mead', bounds=Bounds,\n",
    "#                                 #tol=1e-16,\n",
    "#                                 options={'maxiter':2000, \n",
    "#                                         # 'ftol': 1e-10,\n",
    "#                                         #'maxls': 100,\n",
    "#                                          'disp':True})\n",
    "#     print(result)\n",
    "    \n",
    "#     return result\n",
    "\n",
    "\n",
    "# better_result = sp.optimize.basinhopping(Full_Analysis, new_initial_guess, niter=1, stepsize=10,\n",
    "#                                   minimizer_kwargs=dict(method=custom_min),\n",
    "#                                   accept_test=MyBounds(), disp=True)\n",
    "\n",
    "#Init=np.stack((new_initial_guess,new_initial_guess,new_initial_guess,new_initial_guess,new_initial_guess))\n",
    "Init =np.stack((np.array([6.8811e+02, 7.9165e+01, 9.9711e+02, 1.2211e+02, 1.0051e+02, 8.5666e+00,\n",
    "  4.3092e+00, 6.9957e+00, 4.6705e-05, 1.4132e-03, 1.8037e-02, 2.3725e-01,\n",
    "  4.2467e-01, 3.5548e-01,10**3,10**3,10**3,10**3,10,10,10,10]),\n",
    "                np.array([2.1864e+02, 1.2605e+02, 1.8265e+02, 9.8375e+01, 3.9675e+01,\n",
    "        6.3733e-01, 7.3077e+00, 9.4213e-01, 7.1691e-03, 4.1517e-03,\n",
    "        8.2703e-02, 9.5257e-02, 2.2306e-01, 1.9062e-01, 3.9409e-08,\n",
    "        3.8537e-05, 1.6828e-04, 3.0538e-04, 1.9185e+00, 9.3723e-01,\n",
    "        1.7785e+00, 8.9270e-01]),\n",
    "                np.array([7.1591e+02, 3.1259e+02, 2.8662e+02, 1.6442e+02, 2.6423e+01,\n",
    "       1.2825e+00, 2.1835e+01, 8.7888e+00, 1.7436e-03, 1.0713e-03,\n",
    "       7.9180e-02, 1.0382e-01, 1.9880e-01, 2.2459e-01, 9.7932e-01,\n",
    "       8.6580e-01, 1.0692e+00, 7.9494e-01, 1.0150e-02, 1.1836e-01,\n",
    "       5.4146e-03, 1.0648e-02]),\n",
    "                np.array([2.1864e+02, 1.2605e+02, 1.8265e+02, 9.8375e+01, 3.9675e+01,\n",
    "        6.3733e-01, 7.3077e+00, 9.4213e-01, 7.1691e-03, 4.1517e-03,\n",
    "        8.2703e-02, 9.5257e-02, 2.2306e-01, 1.9062e-01, 3.9409e-08,\n",
    "        3.8537e-05, 1.6828e-04, 3.0538e-04, 1.9185e+00, 9.3723e-01,\n",
    "        1.7785e+00, 8.9270e-01]),\n",
    "                np.array([2.18640000e+02, 1.77321423e+02, 2.97178667e+02, 9.83750000e+01,\n",
    "       2.63635016e+01, 6.37330000e-01, 7.30770000e+00, 9.42130000e-01,\n",
    "       3.04537982e-03, 4.15170000e-03, 1.06443266e-01, 9.52570000e-02,\n",
    "       2.23060000e-01, 1.81494557e-01, 3.94089739e-08, 3.85370000e-05,\n",
    "       1.22411168e+02, 3.05380000e-04, 1.91850000e+00, 2.64375950e+00,\n",
    "       1.24421530e-06, 8.92700000e-01]),\n",
    "                np.array([2.41362341e+02, 1.87465571e+02, 3.06359129e+02, 9.83750000e+01,\n",
    "       2.48031935e+01, 6.37329991e-01, 7.53833099e+00, 9.42130150e-01,\n",
    "       2.29619993e-03, 4.15156353e-03, 9.20363949e-02, 1.25773356e+01,\n",
    "       1.67598599e-01, 2.21462762e-01, 6.68549170e-07, 3.77186998e-05,\n",
    "       3.68790813e+01, 4.29250127e+02, 1.91849997e+00, 1.53394297e-10,\n",
    "       9.99999995e+02, 2.48366338e+01]),\n",
    "                np.array([7.1591e+02, 3.1259e+02, 2.8662e+02, 1.6442e+02, 2.6423e+01,\n",
    "       1.2825e+00, 2.1835e+01, 8.7888e+00, 1.7436e-03, 1.0713e-03,\n",
    "       7.9180e-02, 1.0382e-01, 1.9880e-01, 2.2459e-01, 9.7932e-01,\n",
    "       8.6580e-01, 1.0692e+00, 7.9494e-01, 1.0150e-02, 1.1836e-01,\n",
    "       5.4146e-03, 1.0648e-02]),\n",
    "                np.array([6.88112381e+02, 7.85722370e+01, 9.97105458e+02, 1.22114834e+02,\n",
    "  1.00095980e+02 ,8.71706788e+00 ,4.45444506e+00, 6.72211504e+00,\n",
    "  2.69548038e-03 ,1.94174600e-03, 1.55065050e-02, 2.22532549e-01,\n",
    "  7.02896805e-01, 2.03388273e-01,1e-8,1e-8,1e-8,1e-8,1,1,1,1]),\n",
    "               np.array([1.48665460e+02, 2.19057310e+02 ,2.62024638e+02 ,1.61437274e+02,\n",
    "  2.71802361e+01, 1.24033047e+00, 2.23516416e+01 ,8.45022796e+00,\n",
    "  1.61138979e-02, 2.02249219e-03 ,6.69814861e-02 ,9.14930664e-02,\n",
    "  2.02440304e-01, 2.34608894e-01,1e-4,1e-4,1e-4,1e-4,1,1,1,1])\n",
    "                ,np.array([2.41362341e+02, 1.87465571e+02, 3.06359129e+02, 9.83750000e+01,\n",
    "       2.48031935e+01, 6.37329991e-01, 7.53833099e+00, 9.42130150e-01,\n",
    "       2.29619993e-03, 4.15156353e-03, 9.20363949e-02, 1.25773356e+01,\n",
    "       1.67598599e-01, 2.21462762e-01, 6.68549170e-07, 3.77186998e-05,\n",
    "       3.68790813e+01, 4.29250127e+02, 1.91849997e+00, 1.53394297e-10,\n",
    "       9.99999995e+02, 2.48366338e+01]),\n",
    "                np.array([1.48665460e+02, 2.19057310e+02 ,2.62024638e+02 ,1.61437274e+02,\n",
    "  2.71802361e+01, 1.24033047e+00, 2.23516416e+01 ,8.45022796e+00,\n",
    "  1.61138979e-02, 2.02249219e-03 ,6.69814861e-02 ,9.14930664e-02,\n",
    "  2.02440304e-01, 2.34608894e-01,1,1,1,1,0,0,0,0]),\n",
    "                np.array([1.48665460e+02, 2.19057310e+02 ,2.62024638e+02 ,1.61437274e+02,\n",
    "  2.71802361e+01, 1.24033047e+00, 2.23516416e+01 ,8.45022796e+00,\n",
    "  1.61138979e-02, 2.02249219e-03 ,6.69814861e-02 ,9.14930664e-02,\n",
    "  2.02440304e-01, 2.34608894e-01,1,1,1,1,0,0,0,0]),\n",
    "               np.array([2.41362341e+02, 1.87465571e+02, 3.07070611e+02, 9.83020065e+01,\n",
    "       2.50482813e+01, 6.42417383e-01, 7.53833099e+00, 9.42130411e-01,\n",
    "       2.29472860e-03, 4.38074525e-03, 9.66418938e-02, 1.25773356e+01,\n",
    "       1.67598599e-01, 2.20469165e-01, 6.90292552e-07, 3.77694684e-05,\n",
    "       3.52815567e+01, 4.28978324e+02, 1.90121591e+00, 1.53420388e-10,\n",
    "       9.99999995e+02, 2.48366338e+01]),\n",
    "               np.array([2.41362341e+02, 1.91972736e+02, 3.43129169e+02, 9.81822854e+01,\n",
    "       1.83207981e+01, 6.81612724e-01, 7.53902321e+00, 9.42131958e-01,\n",
    "       2.27827826e-03, 4.54506746e-03, 9.91236679e-02, 1.25773356e+01,\n",
    "       1.67598599e-01, 1.95175950e-01, 9.02941281e-07, 3.89303902e-05,\n",
    "       3.47269915e+01, 4.28930846e+02, 1.32830186e+00, 1.53420388e-10,\n",
    "       9.98838348e+02, 2.57433636e+01]),\n",
    "               np.array([2.41362341e+02, 1.91972736e+02, 3.43129169e+02, 9.81822854e+01,\n",
    "       1.83207981e+01, 6.81612724e-01, 7.53902321e+00, 9.42131958e-01,\n",
    "       2.27827826e-03, 4.54506746e-03, 9.91236679e-02, 1.25773356e+01,\n",
    "       1.67598599e-01, 1.95175950e-01, 9.02941281e-07, 3.89303902e-05,\n",
    "       3.47269915e+01, 4.28930846e+02, 1.32830186e+00, 1.53420388e-10,\n",
    "       9.98838348e+02, 2.57433636e+01]),\n",
    "               np.array([2.31433810e+02, 1.90466280e+02, 3.65867090e+02, 9.83488441e+01,\n",
    "       1.57541270e+01, 1.06325753e+00, 6.83325920e+00, 9.42128706e-01,\n",
    "       1.92504060e-03, 4.24971198e-03, 9.36492001e-02, 1.25773356e+01,\n",
    "       1.48446722e-01, 3.28173163e-01, 1.71043587e-06, 1.02027693e-04,\n",
    "       1.47802800e+02, 4.28158241e+02, 6.11200743e-02, 4.06048066e-01,\n",
    "       9.73777791e+02, 2.74980421e+01]),\n",
    "               np.array([2.31539428e+02, 1.90466280e+02, 3.66655721e+02, 9.83556269e+01,\n",
    "       1.57541270e+01, 1.06415552e+00, 6.83325920e+00, 9.42043599e-01,\n",
    "       1.92504060e-03, 4.24870488e-03, 9.36492001e-02, 1.25773356e+01,\n",
    "       1.48446722e-01, 3.27362408e-01, 1.71043587e-06, 1.03542890e-04,\n",
    "       1.48506875e+02, 4.28158241e+02, 8.34346063e-02, 1.53420388e-10,\n",
    "       5.86913552e+02, 2.77827962e+01]),np.load('de_fitting_5_subc_dti50.npy'),\n",
    "               np.load('de_fitting_7_subc_dti50.npy'),\n",
    "               np.array([3.4504e+02, 1.8893e+02, 3.0881e+02, 9.0579e+01, 2.0876e+01,\n",
    "       5.8554e-01, 7.2718e+00, 9.4413e-01, 2.2475e-03, 4.6180e-03,\n",
    "       9.5867e-02, 4.4390e+02, 1.4111e-01, 1.5644e-01, 1.4847e-06,\n",
    "       9.7867e-05, 7.2554e+01, 6.0210e+02, 3.2340e-01, 7.2727e-03,\n",
    "       6.0175e+02, 2.7397e+02]),\n",
    "               np.load('de_fitting_8_subc_dti50.npy'),\n",
    "            np.load('de_fitting_9_subc_dti50.npy'),\n",
    "                np.load('de_fitting_10_subc_dti50.npy'),\n",
    "                np.load('de_fitting_11_subc_dti50.npy'),\n",
    "                 np.load('de_fitting_12_subc_dti50.npy'),\n",
    "                np.load('de_fitting_13_subc_dti50.npy'),\n",
    "                np.load('de_fitting_14_subc_dti50.npy'),\n",
    "                np.load('de_fitting_16_subc_dti50.npy'),\n",
    "                np.load('de_fitting_17_subc_dti50.npy'),\n",
    "                np.load('de_fitting_18_subc_dti50.npy'),\n",
    "                np.load('de_fitting_19_subc_dti50.npy'),\n",
    "                np.load('de_fitting_20_subc_dti50.npy'),  \n",
    "                             np.load('de_fitting_21_subc_dti50.npy'),  \n",
    "                             np.load('de_fitting_22_subc_dti50.npy'),\n",
    "                np.load('de_fitting_23_subc_dti50.npy'),\n",
    "                np.load('de_fitting_24_subc_dti200.npy'),\n",
    "                np.load('de_fitting_25_subc_dti50.npy'),\n",
    "               np.load('de_fitting_1_subc_dti1.npy'),\n",
    "               np.load('de_fitting_1_subc_dti10.npy'),\n",
    "               np.load('fitting_nosubc_dti1_1.npy')))\n",
    "\n",
    "disp_print = False\n",
    "Args = (eigenvalues, Graph_Kernel, True_Temporal_Spectrum, Min_omega, Max_omega, Delta_omega,\n",
    "        True_Spatial_Spectrum, first_k, last_k, Bins, LSA, Visual, SaveFiles, FilePath, 15, disp_print)\n",
    "\n",
    "Init_mult = np.tile(Init,(6,1))\n",
    "mkl.set_num_threads(1)\n",
    "#Init='sobol' (bad)\n",
    "#try with default strategy (doing)\n",
    "#try higher 0.8 (doing 0.5)\n",
    "#currently trying with full dti, subcortex, dti factor of 50 instead of 200\n",
    "#allow intercept in linear scaling?\n",
    "#change metric back to area between curves?\n",
    "#allow combination with inhibitory spectrum\n",
    "\n",
    "better_result = sp.optimize.differential_evolution(Full_Analysis, bounds=bnds, \n",
    "                                                 args=Args, tol=1e-6, disp=True, init=Init_mult,\n",
    "                                                 maxiter=10000, polish=False, workers=25, recombination=0.8,\n",
    "                                                # str-+ategy='best1exp',\n",
    "                                                mutation=(0.2,1.8))\n",
    "# better_result = sp.optimize.shgo(Full_Analysis, bounds=bnds, \n",
    "#                                                  args=Args, options=dict(f_tol=1e-6, disp=True), workers=20\n",
    "#                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('de_fitting_25_subc_dti50.npy', better_result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(repr(better_result['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is it\n",
    "#better_result=dict(x=np.load('de_fitting_23_subc_dti50.npy'))\n",
    "better_result=dict(x=np.load('de_fitting_24_subc_dti200.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replot fit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-analyze result of minimization procedure\n",
    "\n",
    "#thesis parameters\n",
    "#better_result=dict(x=np.array([1.15357519e+02, 1.80816514e+02, 1.89765888e+02, 2.10306805e+02,\n",
    "#       1.43682388e+01, 1.09130331e+00, 5.36635639e+00, 5.31252166e+00,\n",
    "#       8.37626732e+00, 2.74681544e+00, 3.66503548e-02, 1.00910684e+02,\n",
    "#       4.95497870e+00, 4.47579295e+00]))\n",
    "\n",
    "#better_result=np.load('decent_spatiotemporal_spectrum.npy', allow_pickle=True)[()]\n",
    "#better_result=np.load('decent_spatiotemporal_spectrum_lower_gauss.npy', allow_pickle=True)[()]\n",
    "#better_result=np.load('decent_spatiotemporal_spectrum_even_lower_gauss.npy', allow_pickle=True)[()]\n",
    "#better_result=np.load('decent_spatiotemporal_spectrum_lowest_gauss.npy', allow_pickle=True)[()]\n",
    "#better_result=np.load('decent_spatiotemporal_spectrum_lower_gauss_no_spatial_peak.npy', allow_pickle=True)[()]\n",
    "\n",
    "#IMPORTANT: if using spectra above, run the line below, since they were not done in metres\n",
    "#better_result['x'][8:12]/=1000\n",
    "\n",
    "#better_result=np.load('decent_spatiotemporal_spectrum_first_new_realistic_metres.npy', allow_pickle=True)[()]\n",
    "#better_result=np.load('spatiotemporal_spectrum_empirical_tps.npy', allow_pickle=True)[()]\n",
    "#better_result=np.load('spatiotemporal_spectrum_empirical_sps.npy', allow_pickle=True)[()]\n",
    "#better_result=np.load('first_spatiotemporal_spectrum_empirical_stps.npy', allow_pickle=True)[()]\n",
    "\n",
    "#better_result = np.load('stps_empirical_loglog_median_fitting.npy', allow_pickle=True)[()]\n",
    "# #final paper\n",
    "# result=dict(x=np.array([1.48665460e+02, 2.19057310e+02,2.62024638e+02 ,1.61437274e+02,\n",
    "#  2.71802361e+01, 1.24033047e+00, 2.23516416e+01 ,8.45022796e+00,\n",
    "#  1.61138979e-02, 2.02249219e-03 ,6.69814861e-02 ,9.14930664e-02,\n",
    "#  2.02440304e-01, 2.34608894e-01, 1,1,1,1,0,0,0,0]))\n",
    "# result=dict(x=np.array([1.4867e+02, 2.1906e+02, 2.6202e+02, 1.6144e+02, 2.7185e+01,\n",
    "#        1.2499e+00, 2.2367e+01, 8.4248e+00, 1.6367e-01, 1.5367e-01,\n",
    "#        5.8512e-01, 4.2050e-02, 2.9954e-01, 3.8242e-01, 1.0134e+00,\n",
    "#        1.0133e+00, 1.0782e+00, 1.0243e+00, 1.5275e-01, 1.5259e-01,\n",
    "#        1.5267e-01, 1.5259e-01]))\n",
    "# result=dict(x=np.array([7.1638e+02, 3.1264e+02, 2.8691e+02, 1.6440e+02, 2.6439e+01,\n",
    "#        1.2847e+00, 2.1833e+01, 8.7844e+00, 1.7472e-03, 1.0749e-03,\n",
    "#        7.9154e-02, 1.0383e-01, 1.9918e-01, 2.2551e-01, 9.8274e-01,\n",
    "#        8.6826e-01, 1.0781e+00, 7.9521e-01, 1.0032e-02, 1.1822e-01,\n",
    "#        5.4294e-03, 1.0669e-02]))\n",
    "\n",
    "\n",
    "#result=dict(x=np.load('de_fitting_8_subc_dti50.npy'))\n",
    "#result=dict(x=np.load('de_fitting_1_subc_dti1.npy'))\n",
    "#result=dict(x=np.load('fitting_nosubc_dti1_1.npy'))\n",
    "# better_result=dict(x=np.array([1.48665460e+02, 2.19057310e+02 ,2.62024638e+02 ,1.61437274e+02,\n",
    "#   2.71802361e+01, 1.24033047e+00, 2.23516416e+01 ,8.45022796e+00,\n",
    "#   1.61138979e-02, 2.02249219e-03 ,6.69814861e-02 ,9.14930664e-02,\n",
    "#   2.02440304e-01, 2.34608894e-01,1,1,1,1,0,0,0,0]))\n",
    "\n",
    "#better_result = result\n",
    "\n",
    "# if Graph_Kernel != 'Damped Wave' and len(better_result['x'])<16:\n",
    "#     better_result['x'] = np.concatenate((better_result['x'],[0,0,0,0,1,1,1,1]))\n",
    "    \n",
    "print(Graph_Kernel)    \n",
    "print(better_result['x'])    \n",
    "np.set_printoptions(precision=8)\n",
    "\n",
    "SStates, success = H_Simple_Steady_State(alpha_EE=better_result['x'][0], alpha_IE=better_result['x'][1], alpha_EI=better_result['x'][2], alpha_II=better_result['x'][3], \n",
    "                                         d_e=better_result['x'][4], d_i=better_result['x'][5], P=better_result['x'][6], Q=better_result['x'][7])\n",
    "print(SStates)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SSnr=0\n",
    "# Best suitable steady state: 0, with Ess=0.003813 Iss=0.0522.                       \n",
    "# Dist spatial: 1493, scale params: [6170.0315 1328.5838 4896.9869]                        \n",
    "# Dist temporal: 2092, scale params: [  10.7089   -3.767  -318.5677]\n",
    "sigma_noise=1#0.0000001\n",
    "\n",
    "SStype, found_suitable, JacEigs = GraphWC_Jacobian_TrDet(Laplacian_eigenvalues=eigenvalues, Graph_Kernel=Graph_Kernel, Ess=SStates[0,SSnr], Iss=SStates[1,SSnr],\n",
    "                                     alpha_EE=better_result['x'][0], alpha_IE=better_result['x'][1], alpha_EI=better_result['x'][2], alpha_II=better_result['x'][3], d_e=better_result['x'][4], d_i=better_result['x'][5], \n",
    "                                     sigma_EE=better_result['x'][8], sigma_IE=better_result['x'][9], sigma_EI=better_result['x'][10], sigma_II=better_result['x'][11],  \n",
    "                                     D=1, tau_e=better_result['x'][12], tau_i=better_result['x'][13], \n",
    "                                    aDW_EE=better_result['x'][14],aDW_IE=better_result['x'][15], aDW_EI=better_result['x'][16], aDW_II=better_result['x'][17],\n",
    "                                    bDW_EE=better_result['x'][18], bDW_IE=better_result['x'][19], bDW_EI=better_result['x'][20], bDW_II=better_result['x'][21],\n",
    "                                                         \n",
    "                                                         Visual=True)    \n",
    "\n",
    "\n",
    "E_Spectrum, I_Spectrum = Graph_WC_Spatiotemporal_PowerSpectrum(Laplacian_eigenvalues=eigenvalues, Graph_Kernel=Graph_Kernel, Ess=SStates[0,SSnr], Iss=SStates[1,SSnr],\n",
    "                                        alpha_EE=better_result['x'][0], alpha_IE=better_result['x'][1], alpha_EI=better_result['x'][2], alpha_II=better_result['x'][3], d_e=better_result['x'][4], d_i=better_result['x'][5], \n",
    "                                        sigma_EE=better_result['x'][8], sigma_IE=better_result['x'][9], sigma_EI=better_result['x'][10], sigma_II=better_result['x'][11],  \n",
    "                                        D=1, tau_e=better_result['x'][12], tau_i=better_result['x'][13],\n",
    "                                    aDW_EE=better_result['x'][14],aDW_IE=better_result['x'][15], aDW_EI=better_result['x'][16], aDW_II=better_result['x'][17],\n",
    "                                    bDW_EE=better_result['x'][18], bDW_IE=better_result['x'][19], bDW_EI=better_result['x'][20], bDW_II=better_result['x'][21],\n",
    "                                               \n",
    "                                        sigma_noise_e=sigma_noise, sigma_noise_i=sigma_noise,\n",
    "                                        min_omega=Min_omega, max_omega=Max_omega, delta_omega=Delta_omega,\n",
    "                                        Spatial_Spectrum_Only=False, Visual=True)\n",
    "\n",
    "Spectrum_spatial_only = Graph_WC_Spatiotemporal_PowerSpectrum(Laplacian_eigenvalues=eigenvalues, Graph_Kernel=Graph_Kernel, Ess=SStates[0,SSnr], Iss=SStates[1,SSnr],\n",
    "                                        alpha_EE=better_result['x'][0], alpha_IE=better_result['x'][1], alpha_EI=better_result['x'][2], alpha_II=better_result['x'][3], d_e=better_result['x'][4], d_i=better_result['x'][5], \n",
    "                                        sigma_EE=better_result['x'][8], sigma_IE=better_result['x'][9], sigma_EI=better_result['x'][10], sigma_II=better_result['x'][11],  \n",
    "                                        D=1, tau_e=better_result['x'][12], tau_i=better_result['x'][13],\n",
    "                                    aDW_EE=better_result['x'][14],aDW_IE=better_result['x'][15], aDW_EI=better_result['x'][16], aDW_II=better_result['x'][17],\n",
    "                                    bDW_EE=better_result['x'][18], bDW_IE=better_result['x'][19], bDW_EI=better_result['x'][20], bDW_II=better_result['x'][21],\n",
    "                                               \n",
    "                                        sigma_noise_e=sigma_noise, sigma_noise_i=sigma_noise,\n",
    "                                        min_omega=Min_omega, max_omega=Max_omega, delta_omega=Delta_omega,\n",
    "                                        Spatial_Spectrum_Only=True, Visual=True)\n",
    "\n",
    "\n",
    "\n",
    "#import seaborn as sns\n",
    "#from analysis import find_scaling, NF_to_empirical\n",
    "Gk_E=Spectrum_spatial_only[:,0,0] #Delta_omega*np.sum(Spectrum,axis=0)/np.pi\n",
    "Gk_I=Spectrum_spatial_only[:,1,1]\n",
    "Gw_E=2*np.sum(E_Spectrum,axis=1)\n",
    "Gw_I=2*np.sum(I_Spectrum,axis=1)\n",
    "plt.ion()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Spatial Power Spectrum  $P(k)$\")\n",
    "ax.set_xlabel(\"Spatial Eigenmode ($k$)\")\n",
    "\n",
    "if not fit_to_median:\n",
    "    E_spatial_spectrum = Gk_E\n",
    "    I_spatial_spectrum = Gk_I\n",
    "    SPS_points = np.arange(first_k,last_k)\n",
    "else:\n",
    "    E_spatial_spectrum = np.array([np.median(elem) for elem in np.array_split(Gk_E[first_k:last_k], bins)])\n",
    "    I_spatial_spectrum = np.array([np.median(elem) for elem in np.array_split(Gk_I[first_k:last_k], bins)])\n",
    "    SPS_points = np.array([elem.mean() for elem in np.array_split(np.arange(first_k,last_k), bins)])\n",
    "\n",
    "    \n",
    "# a_matrix_spatial = np.vstack((E_spatial_spectrum,\n",
    "#                               I_spatial_spectrum,\n",
    "#                            #   E_spatial_spectrum*I_spatial_spectrum,\n",
    "#                               np.ones_like(True_Spatial_Spectrum))).T\n",
    "\n",
    "#scale_params_spatial = np.linalg.lstsq(a_matrix_spatial, True_Spatial_Spectrum)[0]    \n",
    "scale_params_spatial = sp.optimize.minimize(find_scaling, x0=[1,0,0], tol=1e-5, args=(E_spatial_spectrum,I_spatial_spectrum,True_Spatial_Spectrum),\n",
    "                                        bounds=[(-1e5,1e5),(-1e5,1e5),(-1e5,1e5)])['x']\n",
    "#scale_params_spatial = np.array([(True_Spatial_Spectrum.mean())/(E_spatial_spectrum.mean())])\n",
    "\n",
    "# n_spatial = len(True_Spatial_Spectrum)    \n",
    "# a_spatial = (n_spatial*np.dot(E_spatial_spectrum,True_Spatial_Spectrum)-np.sum(True_Spatial_Spectrum)*np.sum(E_spatial_spectrum))/(n_spatial*np.dot(E_spatial_spectrum,E_spatial_spectrum)-np.sum(E_spatial_spectrum)**2)\n",
    "# b_spatial = (np.sum(True_Spatial_Spectrum)-a_spatial*np.sum(E_spatial_spectrum))/n_spatial\n",
    "# scale_params_spatial = np.array([a_spatial,b_spatial])\n",
    "\n",
    "current_spatial_spectrum = NF_to_empirical(scale_params_spatial,\n",
    "                                           E_spatial_spectrum,\n",
    "                                           I_spatial_spectrum)\n",
    "\n",
    "#to avoid log10 throwing tantrums. but of course no \"good\" spectrum should have negative values                    \n",
    "current_spatial_spectrum[current_spatial_spectrum<=0] = 1e-10\n",
    "\n",
    "data_1=np.vstack((SPS_points, np.log10(True_Spatial_Spectrum))).T\n",
    "data_2=np.vstack((SPS_points, np.log10(current_spatial_spectrum))).T   \n",
    "\n",
    "dist_spatial = (1+sm.area_between_two_curves(data_1,data_2))**1\n",
    "\n",
    "#np.linalg.norm(np.log10(True_Spatial_Spectrum) - np.log10(current_spatial_spectrum), ord=1)#sm.area_between_two_curves(data_1,data_2)#np.linalg.norm((np.log10(True_Spatial_Spectrum) - np.log10(current_spatial_spectrum), ord=1)#np.linalg.norm(True_Spatial_Spectrum - a_spatial*current_spatial_spectrum-b_spatial, ord=2)#1-sp.stats.ks_2samp(True_Spatial_Spectrum, current_spatial_spectrum*a_spatial+b_spatial)[1]#1-np.ma.corrcoef(True_Spatial_Spectrum, current_spatial_spectrum)[0,1]#\n",
    "\n",
    "dist_spatial += (1+np.linalg.norm(np.log10(True_Spatial_Spectrum)-np.log10(current_spatial_spectrum), ord=2))**2\n",
    "\n",
    "dist_spatial += (1+np.linalg.norm((np.log10(True_Spatial_Spectrum[1:])-np.log10(True_Spatial_Spectrum[:-1]))-(np.log10(current_spatial_spectrum[1:])-np.log10(current_spatial_spectrum[:-1])), ord=2))**2\n",
    "\n",
    "print(\"spatial scale factors: {}\".format(scale_params_spatial))\n",
    "print(\"spatial distance: {}\".format(dist_spatial))\n",
    "\n",
    "ax.loglog(np.arange(first_k, last_k), empirical_SPS, marker='s', linestyle='', markersize=2, zorder=0, color=[0.267004, 0.004874, 0.329415, 1.])\n",
    "plot_bins = np.unique(np.logspace(0, np.log10(20000), num=300, dtype=int))[:-1]\n",
    "y_bins = np.unique(np.logspace(0, np.log10(18715), num=200, dtype=int))[:-1]\n",
    "ax.hist2d(np.arange(first_k, last_k), empirical_SPS, (plot_bins, y_bins), cmap='viridis',zorder=1,cmin=2)\n",
    "\n",
    "ax.loglog(np.arange(1,len(eigenvalues)),  NF_to_empirical(scale_params_spatial,Gk_E,Gk_I)[1:], zorder=3,color='red', linestyle='--', linewidth=2)\n",
    "plt.errorbar(x=binned_SPS_points, y=binned_SPS, yerr=binned_SPS_err, zorder=2, fmt='ys',markersize=5)\n",
    "\n",
    "print(sp.stats.ks_2samp(empirical_SPS,  current_spatial_spectrum))\n",
    "print(sp.stats.ks_2samp(True_Spatial_Spectrum, current_spatial_spectrum))\n",
    "      \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.set_title(\"Temporal Power Spectrum  $T(\\omega)$\")\n",
    "ax.set_xlabel(\"Frequency (Hz)\")\n",
    "\n",
    "freqs=np.arange(Min_omega,Max_omega,Delta_omega)\n",
    "\n",
    "# a_matrix_temporal = np.vstack((Gw_E,\n",
    "#                                Gw_I,\n",
    "#                               # Gw_E*Gw_I,\n",
    "#                                np.ones_like(True_Temporal_Spectrum))).T\n",
    "\n",
    "# scale_params_temporal = np.linalg.lstsq(a_matrix_temporal, True_Temporal_Spectrum)[0]\n",
    "scale_params_temporal = sp.optimize.minimize(find_scaling, x0=[1,0,0], tol=1e-5, args=(Gw_E,\n",
    "                                                Gw_I,True_Temporal_Spectrum),\n",
    "                                        bounds=[(0,1e5),(-1e5,1e5),(-1e5,1e5)])['x']\n",
    "#scale_params_temporal = np.array([(True_Temporal_Spectrum.mean())/(Gw_E.mean())])\n",
    "\n",
    "current_temporal_spectrum = NF_to_empirical(scale_params_temporal,\n",
    "                                            Gw_E, Gw_I)\n",
    "\n",
    "#to avoid log10 throwing tantrums. but of course no \"good\" spectrum should have negative values\n",
    "#current_temporal_spectrum[current_temporal_spectrum<=0] = 1e-10\n",
    "\n",
    "data_3=np.vstack((np.arange(Min_omega,Max_omega,Delta_omega),np.log10(True_Temporal_Spectrum))).T\n",
    "data_4=np.vstack((np.arange(Min_omega,Max_omega,Delta_omega),np.log10(current_temporal_spectrum))).T        \n",
    "dist_temporal = (1+sm.area_between_two_curves(data_3,data_4))**3#np.linalg.norm(np.log10(True_Temporal_Spectrum) - np.log10(current_temporal_spectrum), ord=1)#sm.area_between_two_curves(data_3,data_4)#np.linalg.norm(True_Temporal_Spectrum - current_temporal_spectrum, ord=1)##np.linalg.norm(True_Temporal_Spectrum - a_temporal*current_temporal_spectrum-b_temporal, ord=2)#1-sp.stats.ks_2samp(True_Temporal_Spectrum, current_temporal_spectrum*a_temporal+b_temporal)[1]#1-np.ma.corrcoef(True_Temporal_Spectrum, current_temporal_spectrum)[0,1]#\n",
    "dist_temporal += (1+np.linalg.norm(np.log10(True_Temporal_Spectrum)-np.log10(current_temporal_spectrum), ord=2))**3\n",
    "\n",
    "dist_temporal += (1+np.linalg.norm((np.log10(True_Temporal_Spectrum[1:])-np.log10(True_Temporal_Spectrum[:-1]))-(np.log10(current_temporal_spectrum[1:])-np.log10(current_temporal_spectrum[:-1])), ord=2))**3\n",
    "\n",
    "print(\"temporal scale factor: {}\".format(scale_params_temporal))\n",
    "print(\"temporal distance: {}\".format(dist_temporal))\n",
    "\n",
    "print(np.ma.corrcoef(True_Temporal_Spectrum, current_temporal_spectrum))\n",
    "print(np.ma.corrcoef(True_Spatial_Spectrum, current_spatial_spectrum))\n",
    "\n",
    "print(sp.stats.ks_2samp(True_Temporal_Spectrum, current_temporal_spectrum))\n",
    "\n",
    "ax.loglog(freqs/(2*np.pi),\n",
    "            current_temporal_spectrum)\n",
    "ax.loglog(freqs/(2*np.pi), \n",
    "            True_Temporal_Spectrum)\n",
    "\n",
    "#np.save('decent_spatiotemporal_spectrum.npy', better_result)\n",
    "print(better_result['x'])\n",
    "print(f\"total dist {dist_spatial+dist_temporal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#np.load('decent_spatiotemporal_spectrum_lower_gauss.npy')[()]['x']-better_result['x']\n",
    "#current best (loglog space fitting)\n",
    "[ 1.06682212e+03,  1.73415339e+02,  2.92699896e+03,  2.95074005e+02,\n",
    "  9.07838853e+01,  3.19257788e+00,  7.47262994e+00, -1.76660214e-02,\n",
    "  5.43684383e-04, -1.75210509e-09,  5.52478781e-04,  5.40207870e+04,\n",
    "  9.29655089e+00,  3.27876977e-01]\n",
    "#logspace excellent s2.16 t0.86 (kstat pval 0.21 0.68)\n",
    "better_result['x'] [ 1.60298254e+03,  1.84931805e+02,  2.99551387e+03,  2.80138120e+02,\n",
    "  9.29297308e+01,  1.22714483e+00,  7.24240357e+00,  3.71750330e-01,\n",
    "  4.34632128e-04,  2.05916610e-05,  6.11898211e-04, -3.38503489e+10,\n",
    "  6.93229886e+00,  1.51916190e-01]\n",
    "#np.save('stps_empirical_first_loglog_median_fitting.npy', better_result)\n",
    "[6.32352428e+02, 7.93766496e+01, 3.47535746e+02, 1.07039076e+02,\n",
    "       1.56586247e+02, 4.22226636e+00, 1.54479298e+01, 2.49662094e+01,\n",
    "       4.31042051e-02, 2.44534241e-03, 4.77988694e-02, 5.17697376e-02,\n",
    "       1.37486268e-01, 6.30906093e-01])\n",
    "\n",
    "better_result['x']=[ 1.06682212e+03,  1.73415339e+02,  2.92699896e+03,  2.95074005e+02,\n",
    "  9.07838853e+01,  3.19257788e+00,  7.47262994e+00, -1.76660214e-02,\n",
    "  5.43684383e-04, -1.75210509e-09,  5.52478781e-04,  5.40207870e+04,\n",
    "  9.29655089e+00,  3.27876977e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#np.save('stps_empirical_loglog_median_fitting.npy', better_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#comparison of numerical (nonlinear) simulations and (linearized) semi analytic results \n",
    "#(any parameter set; grid laplacian only):\n",
    "#\n",
    "#1) test for steady state calculation: simulate (with no noise) on a grid, start directly from SS solution.\n",
    "#2) test for stability/instability/oscillations: add noise in the grid simulation for specific parameter sets\n",
    "#3) test for power spectrum calculation: run noisy grid simulation and compare prediction with measured PS (see handwritten notes)\n",
    "#\n",
    "################################################################################################\n",
    "#testing the correctness of the parameter fit procedure(full analysis + minimization algorithm) result\n",
    "#(intended mainly for the better_result parameter set)\n",
    "#\n",
    "#retest minimization algorithm, with objective the current best-fit PS obtained and random initial condition. see if other parameter combinations give the same, ideally converge to same par. set\n",
    "#\n",
    "#check (via effect on linearized Jk eigenvalues) if a nearby hopf bifurcation can be induced by changing P or some other parameter \n",
    "#(to ask rikkert: do we want this as a prior requirement in minimization? would be hard but doable)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1D predictions\n",
    "#set up 1D-specific simulation parameters and WCM propagators\n",
    "one_dim=True\n",
    "syn=30\n",
    "#if making plot from connectome minimization, need to change this value to the number of connectome nodes\n",
    "gridsize=1000#len(eigenvalues)\n",
    "h=0.001\n",
    "#Min_omega=5*(2*np.pi)\n",
    "#Max_omega=50*(2*np.pi)\n",
    "#Delta_omega=0.1*(2*np.pi)\n",
    "\n",
    "Graph_Kernel='Damped Wave'\n",
    "one_dim_eigenvalues, one_dim_eigenvectors = one_dim_Laplacian_eigenvalues(gridsize, h, syn, vecs=True)\n",
    "#one_dim_eigenvalues2 = one_dim_Laplacian_eigenvalues(gridsize, h, syn)\n",
    "\n",
    "#re-analyze result of minimization procedure\n",
    "#better_result=np.load('decent_spatiotemporal_spectrum.npy')[()]\n",
    "\n",
    "#better_result=np.load('decent_spatiotemporal_spectrum_lower_gauss.npy')[()]\n",
    "\n",
    "#better_result=np.load('decent_spatiotemporal_spectrum_even_lower_gauss.npy')[()]\n",
    "\n",
    "#better_result=np.load('decent_spatiotemporal_spectrum_lowest_gauss.npy')[()]\n",
    "\n",
    "#thesis result\n",
    "#better_result=dict(x=np.array([1.15357519e+02, 1.80816514e+02, 1.89765888e+02, 2.10306805e+02,\n",
    "#       1.43682388e+01, 1.09130331e+00, 5.36635639e+00, 5.31252166e+00,\n",
    "#       8.37626732e+00, 2.74681544e+00, 3.66503548e-02, 1.00910684e+02,\n",
    "#       4.95497870e+00, 4.47579295e+00]))\n",
    "\n",
    "#better_result=dict(x=np.array([1.15357519e+02, 1.80816514e+02, 1.89765888e+02, 2.10306805e+02,\n",
    "#       1.43682388e+01, 1.09130331e+00, 5.36635639e+00, 5.31252166e+00,\n",
    "#       8.37626732e+00, 2.74681544e+00, 3.66503548e-02, 1.00910684e+02,\n",
    "#       4.95497870e+00, 4.47579295e+00]))f\n",
    "\n",
    "aEE=better_result['x'][0]\n",
    "aIE=better_result['x'][1]\n",
    "aEI=better_result['x'][2]\n",
    "aII=better_result['x'][3]\n",
    "dE=better_result['x'][4]\n",
    "dI=better_result['x'][5]\n",
    "P=better_result['x'][6]\n",
    "Q=better_result['x'][7]\n",
    "sEE=better_result['x'][8]\n",
    "sIE=better_result['x'][9]\n",
    "sEI=better_result['x'][10]\n",
    "sII=better_result['x'][11]\n",
    "D=1\n",
    "tE=better_result['x'][12]\n",
    "tI=better_result['x'][13]\n",
    "aDWEE=better_result['x'][14]\n",
    "aDWIE=better_result['x'][15]\n",
    "aDWEI=better_result['x'][16]\n",
    "aDWII=better_result['x'][17]\n",
    "bDWEE=better_result['x'][18]\n",
    "bDWIE=better_result['x'][19]\n",
    "bDWEI=better_result['x'][20]\n",
    "bDWII=better_result['x'][21]\n",
    "\n",
    "snE=0.0000001\n",
    "#snE=0.0001\n",
    "snI=snE\n",
    "\n",
    "#given parameters, calculate steady states\n",
    "steady_states, success = H_Simple_Steady_State(aEE, aIE, aEI, aII, dE, dI, P, Q)\n",
    "#steady_states = np.array([[0.003813,0.0522]]).T\n",
    "print(steady_states)\n",
    "#[0.020156003894108397,0.04507043633755498]\n",
    "\n",
    "#for each steady state, compute linear stability and power spectrum\n",
    "if success==True:\n",
    "    nrSS=len(steady_states[0])\n",
    "    allG = np.empty((nrSS,int((Max_omega-Min_omega)/Delta_omega),gridsize), dtype=float)\n",
    "    allGI = np.empty((nrSS,int((Max_omega-Min_omega)/Delta_omega),gridsize), dtype=float)\n",
    "    SStypes=np.zeros(nrSS)\n",
    "    for ss in range(nrSS):\n",
    "\n",
    "        Ess = steady_states[0,ss]\n",
    "        Iss = steady_states[1,ss]\n",
    "\n",
    "        SStypes[ss], found_suitable, JacEigs = GraphWC_Jacobian_TrDet(one_dim_eigenvalues, Graph_Kernel, Ess, Iss,\n",
    "                                         alpha_EE=aEE, alpha_IE=aIE, alpha_EI=aEI, alpha_II=aII, d_e=dE, d_i=dI,\n",
    "                                         sigma_EE=sEE, sigma_IE=sIE, sigma_EI=sEI, sigma_II=sII, D=D, \n",
    "                                         tau_e=tE, tau_i=tI,\n",
    "                                                                      \n",
    "                                    aDW_EE=aDWEE,aDW_IE=aDWIE, aDW_EI=aDWEI, aDW_II=aDWII,\n",
    "                                    bDW_EE=bDWEE, bDW_IE=bDWIE, bDW_EI=bDWEI, bDW_II=bDWII,\n",
    "                                               Visual=True) \n",
    "\n",
    "        #allG[ss,:,:] = \n",
    "        allG[ss,:,:], allGI[ss,:,:] =Graph_WC_Spatiotemporal_PowerSpectrum(one_dim_eigenvalues, Graph_Kernel, Ess, Iss,\n",
    "                                                aEE, aIE, aEI, aII, dE, dI,\n",
    "                                                 sEE, sIE, sEI, sII, D, \n",
    "                                                 tE, tI,\n",
    "                                                \n",
    "                                    aDWEE,aDWIE, aDWEI, aDWII,\n",
    "                                    bDWEE, bDWIE, bDWEI, bDWII,        \n",
    "                                                 snE, snI, \n",
    "                                                  Min_omega, Max_omega, Delta_omega,          \n",
    "                                                   Spatial_Spectrum_Only=False, Visual=True)\n",
    "        \n",
    "        sspectrum =Graph_WC_Spatiotemporal_PowerSpectrum(one_dim_eigenvalues, Graph_Kernel, Ess, Iss,\n",
    "                                                aEE, aIE, aEI, aII, dE, dI,\n",
    "                                                 sEE, sIE, sEI, sII, D, \n",
    "                                                 tE, tI,\n",
    "                                                         \n",
    "                                    aDWEE,aDWIE, aDWEI, aDWII,\n",
    "                                    bDWEE, bDWIE, bDWEI, bDWII,   \n",
    "                                                 snE, snI,         \n",
    "                                                   Spatial_Spectrum_Only=True, Visual=True)\n",
    "        \n",
    "\n",
    "        \n",
    "        Func_Conn_prediction = Functional_Connectivity(one_dim_eigenvectors, sspectrum[:,0,0], Visual=True)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('fun_FC.npy',FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1D grid simulation (nonlinear wilson-cowan)\n",
    "#thesis values\n",
    "#Time=100\n",
    "#Delta_t=0.01\n",
    "plt.close('all')\n",
    "#more recent param set values\n",
    "#Time=3\n",
    "#Delta_t=0.0001\n",
    "\n",
    "# #duration and timestep (empirical loglog median fitting)\n",
    "# Time=10\n",
    "# Delta_t=0.00005\n",
    "\n",
    "# #duration and timestep (empirical spatial only linear scaling)\n",
    "# Time=50\n",
    "# Delta_t=0.0005\n",
    "\n",
    "# #parameters of 1D graph (nonlocal synapses, grid size, grid spacing)\n",
    "# syn=0\n",
    "# gridsize=1000\n",
    "# h=0.003\n",
    "\n",
    "Time = 10\n",
    "Delta_t = 0.0001\n",
    "\n",
    "nrSS=0\n",
    "Ess = steady_states[0,nrSS]\n",
    "Iss = steady_states[1,nrSS]    \n",
    "# Best suitable steady state: 0, with Ess=0.003813 Iss=0.0522.                       \n",
    "# Dist spatial: 1493, scale params: [6170.0315 1328.5838 4896.9869]                        \n",
    "# Dist temporal: 2092, scale params: [  10.7089   -3.767  -318.5677]\n",
    "\n",
    "E_total = Graph_Wilson_Cowan_Model(Ess, Iss, Time, Delta_t,                          \n",
    "                         aEE, aIE, aEI, aII,\n",
    "                         sEE, sIE, sEI, sII, D,\n",
    "                         dE, dI, P, Q, tE, tI, \n",
    "                                    aDWEE,aDWIE, aDWEI, aDWII,\n",
    "                                    bDWEE, bDWIE, bDWEI, bDWII,             \n",
    "                        snE, snI, Graph_Kernel,                                  \n",
    "                         one_dim=True, syn=syn, gridsize=gridsize, h=h,\n",
    "                         Visual=False, SaveActivity=False, Filepath=' ')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#activity analysis and comparison with prediction\n",
    "#thesis values\n",
    "#Max_omega=50\n",
    "#Delta_omega=0.1\n",
    "\n",
    "#Min_omega=1*(2*np.pi)\n",
    "#Max_omega=100*(2*np.pi)\n",
    "plt.close('all')\n",
    "PS, TPS, FC = Activity_Analysis(Ess, Iss, Delta_t, \n",
    "                            aEE, aIE, aEI, aII,\n",
    "                            sEE, sIE, sEI, sII, D,\n",
    "                            dE, dI, P, Q, tE, tI, \n",
    "                                \n",
    "                                    aDWEE,aDWIE, aDWEI, aDWII,\n",
    "                                    bDWEE, bDWIE, bDWEI, bDWII,        \n",
    "                            snE, snI, Graph_Kernel,                             \n",
    "                           E_total=E_total,    compute_FC=True,                                              \n",
    "                            prediction=True, min_omega=Min_omega, max_omega=Max_omega, delta_omega=Delta_omega,                        \n",
    "                            one_dim=True, syn=syn, gridsize=gridsize, h=h,                           \n",
    "                            Visual=True, Save_Results=False, Filepath=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Human connectome simulation (linearized wilson-cowan: perturbation about steady state)\n",
    "#thesis time and timestep values\n",
    "#Time=100\n",
    "#Delta_t=0.01\n",
    "#more recent work\n",
    "Time=2\n",
    "Delta_t=0.0001\n",
    "\n",
    "#final (empirical)\n",
    "Time=100\n",
    "Delta_t=0.0001\n",
    "\n",
    "#new\n",
    "#final (empirical)\n",
    "Time=1\n",
    "Delta_t=0.0001\n",
    "\n",
    "nrSS=0\n",
    "Ess = steady_states[0,nrSS]\n",
    "Iss = steady_states[1,nrSS]    \n",
    "\n",
    "SPS_sims=[]\n",
    "TPS_sims=[]\n",
    "#for sims in range(3):\n",
    "\n",
    "u_0=np.zeros(len(eigenvalues))#np.zeros(gridsize)#(-0.1/499**2)*(np.arange(gridsize)-499)**2 + 0.1 \n",
    "u_0[6369]=50\n",
    "u_1=graph_propagator_test(np.dot(eigenvectors.T,u_0), Time=2, Delta_t=1, kernel_param=50/1000000, \n",
    "                          Graph_Kernel='Gaussian', sigma_noise=0.0,\n",
    "                          one_dim=False, syn=0, gridsize=0,  h=0, eigvals=eigenvalues, GF_domain=True,                         \n",
    "                          Visual=False, SaveActivity=False, Filepath=' ', NSim=0)[:,1]\n",
    "\n",
    "\n",
    "Beta_E_total = Linearized_GLDomain_Wilson_Cowan_Model(Ess, Iss, Time, Delta_t,                          \n",
    "                     aEE, aIE, aEI, aII,\n",
    "                     sEE, sIE, sEI, sII, D,\n",
    "                     dE, dI, P, Q, tE, tI, \n",
    "                                aDWEE,aDWIE, aDWEI, aDWII,\n",
    "                                bDWEE, bDWIE, bDWEI, bDWII,                                                            \n",
    "                   # snE, snI, \n",
    "                    0,0,\n",
    "                        Graph_Kernel,\n",
    "                     one_dim=False, eigvals=eigenvalues, eigvecs=None,\n",
    "                     Visual=False, SaveActivity=False, Filepath=' ',\n",
    "                                                      \n",
    "                                                      beta_E_0=u_1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "PS_full, TPS_full = Activity_Analysis(Ess, Iss, Delta_t,\n",
    "                                   aEE, aIE, aEI, aII,\n",
    "                                   sEE, sIE, sEI, sII, D,\n",
    "                                   dE, dI, P, Q, tE, tI, \n",
    "                                          \n",
    "                                    aDWEE,aDWIE, aDWEI, aDWII,\n",
    "                                    bDWEE, bDWIE, bDWEI, bDWII,  \n",
    "                                          \n",
    "                                    snE, snI, Graph_Kernel,\n",
    "                                \n",
    "                                 beta_E_total=Beta_E_total,\n",
    "                                   \n",
    "                                   prediction=True, min_omega=Min_omega, max_omega=Max_omega, delta_omega=Delta_omega,\n",
    "                                      temporal_downsampling=10,\n",
    "                                 #  Spatial_scaling=[a_spatial,b_spatial], Temporal_scaling=[a_temporal,b_temporal],\n",
    "                                   \n",
    "                                   one_dim=False, syn=syn, gridsize=gridsize, h=h,\n",
    "                                      \n",
    "                                   eigvals=eigenvalues, eigvecs=None,\n",
    "                                   \n",
    "                                   Visual=True, Save_Results=False, Filepath=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SPS_sims=[]\n",
    "Time=100\n",
    "Delta_t=0.0001\n",
    "\n",
    "nrSS=0\n",
    "Ess = steady_states[0,nrSS]\n",
    "Iss = steady_states[1,nrSS]  \n",
    "for sims in range(3):\n",
    "    Beta_E_total = np.load('/home/aqil/NFModel/Beta_E_total'+str(sims)+'.npy')\n",
    "\n",
    "    PS_full, TPS_full = Activity_Analysis(Ess, Iss, Delta_t,\n",
    "                                   aEE, aIE, aEI, aII,\n",
    "                                   sEE, sIE, sEI, sII, D,\n",
    "                                   dE, dI, P, Q, tE, tI, snE, snI, Graph_Kernel,\n",
    "                                \n",
    "                                   beta=True, beta_E_total=Beta_E_total,\n",
    "                                   \n",
    "                                   prediction=True, min_omega=Min_omega, max_omega=Max_omega, delta_omega=Delta_omega,\n",
    "                                      \n",
    "                                 #  Spatial_scaling=[a_spatial,b_spatial], Temporal_scaling=[a_temporal,b_temporal],\n",
    "                                   \n",
    "                                   one_dim=False, syn=syn, gridsize=gridsize, h=h,\n",
    "                                      \n",
    "                                   eigvals=eigenvalues, eigvecs=None,\n",
    "                                   \n",
    "                                   Visual=True, Save_Results=False, Filepath=' ')    \n",
    "\n",
    "    \n",
    "    SPS_sims.append(PS_full)\n",
    "\n",
    "    del Beta_E_total    \n",
    "    \n",
    "PS_full = np.median(SPS_sims, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save('/home/aqil/NFModel/simulations_median_PS.npy', PS_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.ion()\n",
    "plt.figure()\n",
    "\n",
    "PS_sims_rescaled = NF_to_empirical(scale_params_spatial,PS_full,0)[first_k:last_k]\n",
    "analytic_PS_rescaled = NF_to_empirical(scale_params_spatial,Gk_E,Gk_I)[first_k:last_k]\n",
    "\n",
    "binned_SPS_sim = np.array([np.median(elem) for elem in np.array_split(PS_sims_rescaled, bins)])\n",
    "binned_SPS_err_sim = np.array([sp.stats.sem(elem) for elem in np.array_split(PS_sims_rescaled, bins)])\n",
    "\n",
    "plt.loglog(np.arange(first_k, last_k),PS_sims_rescaled, marker='s', linestyle='', markersize=2, zorder=1, color=[0.267004, 0.004874, 0.329415, 1.], label='Simulation PS')\n",
    "plt.hist2d(np.arange(first_k, last_k),PS_sims_rescaled,(plot_bins, y_bins), cmap='viridis',zorder=2,cmin=2)\n",
    "plt.loglog(np.arange(first_k, last_k), analytic_PS_rescaled, zorder=4,color='black', linestyle='--', linewidth=2, label = 'Predicted PS')\n",
    "plt.errorbar(x=binned_SPS_points, y=binned_SPS_sim, yerr=binned_SPS_err_sim, zorder=3, fmt='ro-',markersize=3, label='Simulation binned median PS')\n",
    "plt.legend(prop={'size': 12})\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.loglog(np.arange(first_k, last_k), empirical_SPS, marker='s', linestyle='', markersize=2, zorder=0, color=[0.267004, 0.004874, 0.329415, 1.], label='fMRI PS')\n",
    "plt.hist2d(np.arange(first_k, last_k), empirical_SPS, (plot_bins, y_bins), cmap='viridis',zorder=1,cmin=2)\n",
    "plt.loglog(np.arange(first_k, last_k), analytic_PS_rescaled, zorder=3,color='black', linestyle='--', linewidth=2, label = 'Predicted PS')\n",
    "plt.errorbar(x=binned_SPS_points, y=binned_SPS, yerr=binned_SPS_err, zorder=2, fmt='yo-',markersize=3, label='fMRI binned median PS')\n",
    "plt.legend(prop={'size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.loglog(np.arange(first_k, last_k), analytic_PS_rescaled, zorder=2,color='black', linestyle='--', linewidth=3, label = 'Prediction', alpha=0.65)\n",
    "plt.errorbar(x=binned_SPS_points, y=binned_SPS_sim, yerr=0, fmt='ro-',markersize=4, label='Simulation',zorder=1, alpha=0.65)\n",
    "plt.errorbar(x=binned_SPS_points, y=binned_SPS, yerr=0, fmt='co-',markersize=4.5, label='Resting-state fMRI', zorder=0)\n",
    "plt.xlabel(\"Spatial Eigenmode ($k$)\")\n",
    "plt.ylabel(\"Power ($P(k)$)\")\n",
    "plt.legend(prop={'size': 18}, loc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#covariance = np.cov(timecourse)\n",
    "covariance[covariance==0] = 1e-10\n",
    "covariance[covariance==1] = 1e-10\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(np.dot(np.diag(np.power(np.diag(covariance),-0.5)),np.dot(covariance,np.diag(np.power(np.diag(covariance),-0.5)))),\n",
    "              vmin=-1,\n",
    "              vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Func_Conn_prediction = Functional_Connectivity(eigenvectors, NF_to_empirical(scale_params_spatial,Gk_E,Gk_I), one_dim=False, Visual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "0.0001 10 slightly too high (time interval not small enough)\n",
    "0.00008 8 slightly too high (time interval not small enough?)\n",
    "0.00005 10 not doable\n",
    "0.00005 7 slightly too low\n",
    "0.00005 5 slightly too low (duration too short?)\n",
    "0.00001 1 white noise like (low) (duration too short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#further verification: 1D grid simulation (linearized wilson-cowan: perturbation about steady state)\n",
    "\n",
    "#duration and timestep\n",
    "Time=10\n",
    "Delta_t=0.00001\n",
    "\n",
    "#parameters of 1D graph (nonlocal synapses, grid size, grid spacing)\n",
    "#syn=150\n",
    "#gridsize=1000\n",
    "#h=1\n",
    "\n",
    "nrSS=0\n",
    "Ess = steady_states[0,nrSS]\n",
    "Iss = steady_states[1,nrSS]   \n",
    "\n",
    "\n",
    "\n",
    "Beta_E_total_1D = Linearized_GLDomain_Wilson_Cowan_Model(Ess, Iss, Time, Delta_t,                          \n",
    "                         aEE, aIE, aEI, aII,\n",
    "                         sEE, sIE, sEI, sII, D,\n",
    "                         dE, dI, P, Q, tE, tI,\n",
    "                                                         \n",
    "                                            aDWEE,aDWIE, aDWEI, aDWII,\n",
    "                                bDWEE, bDWIE, bDWEI, bDWII,  \n",
    "                                                         snE, snI, Graph_Kernel,\n",
    "                         one_dim=True, syn=syn, gridsize=gridsize, h=h,\n",
    "                         eigvals=None, eigvecs=None,\n",
    "                         Visual=False, SaveActivity=False, Filepath=' ') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#activity analysis of linearized model and comparison with prediction (perturbation about steady state)\n",
    "#thesis values\n",
    "#Max_omega=50\n",
    "#Delta_omega=0.1\n",
    "plt.close('all')\n",
    "#Max_omega=3000\n",
    "#Delta_omega=0.5\n",
    "\n",
    "PS_full_1D, TPS_full_1D = Activity_Analysis(Ess, Iss, Delta_t,\n",
    "                                   aEE, aIE, aEI, aII,\n",
    "                                   sEE, sIE, sEI, sII, D,\n",
    "                                   dE, dI, P, Q, tE, tI,\n",
    "                                    aDWEE,aDWIE, aDWEI, aDWII,\n",
    "                                bDWEE, bDWIE, bDWEI, bDWII,          \n",
    "                                    snE, snI, Graph_Kernel,\n",
    "                                \n",
    "                                  beta_E_total=Beta_E_total_1D,\n",
    "                                   \n",
    "                                   prediction=True, max_omega=Max_omega, delta_omega=Delta_omega,\n",
    "                                   \n",
    "                                   one_dim=True, syn=syn, gridsize=gridsize, h=h,\n",
    "                                      \n",
    "                                   eigvals=None, eigvecs=None,\n",
    "                                   \n",
    "                                   Visual=True, Save_Results=False, Filepath=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MISC\n",
    "#Beta_E_total=np.load('G:/Macbook Stuff/Simulation Results/Decent spatiotemporal spectrum activity.npy')\n",
    "#del Beta_E_total\n",
    "#del eigenvectors\n",
    "#del connectome_activity\n",
    "#np.save('G:/Macbook Stuff/Simulation Results/Decent spatiotemporal spectrum activity.npy', Beta_E_total)\n",
    "#print(len(Beta_E_total[0]))\n",
    "#print(Beta_E_total[0])\n",
    "with h5py.File(\"G:/Macbook Stuff/Simulation Results/Decent spatiotemporal spectrum activity.h5\") as hf:\n",
    "    if \"Activity\" not in list(hf.keys()):\n",
    "        #connectome_activity=np.dot(eigenvectors,Beta_E_total)\n",
    "        hf.create_dataset(\"Activity\",  data=connectome_activity)\n",
    "    else:\n",
    "        print(\"Warning: overwriting results of a previous simulation.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "diag_prop_EE = sp.sparse.diags(GraphKernel(eigenvalues,0.5*sEE**2, type=Graph_Kernel ,a=aDWEE,b=bDWEE)).toarray()\n",
    "propagator_EE = np.dot(eigenvectors, np.dot(diag_prop_EE,eigenvectors.T))\n",
    "u0=np.random.rand(len(eigenvalues))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit(lambda: propagator_EE @ u0, number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit(lambda: np.dot(propagator_EE,u0), number=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nonlinear connectome simulation\n",
    "nrSS=0\n",
    "Ess = steady_states[0,nrSS]\n",
    "Iss = steady_states[1,nrSS]    \n",
    "Time=10\n",
    "Delta_t=0.0001\n",
    "\n",
    "E_total = Graph_Wilson_Cowan_Model(Ess, Iss, Time, Delta_t,                          \n",
    "                         aEE, aIE, aEI, aII,\n",
    "                         sEE, sIE, sEI, sII, D,\n",
    "                         dE, dI, P, Q, tE, tI, \n",
    "                                                                  \n",
    "                                    aDWEE,aDWIE, aDWEI, aDWII,\n",
    "                                    bDWEE, bDWIE, bDWEI, bDWII,  \n",
    "                                                     \n",
    "                        snE, snI, Graph_Kernel,                                  \n",
    "                         one_dim=False, eigvals=eigenvalues, eigvecs=eigenvectors,\n",
    "                         Visual=True, SaveActivity=False, Filepath=' ')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PS_full, TPS_full = Activity_Analysis(Ess, Iss, Delta_t,\n",
    "                                   aEE, aIE, aEI, aII,\n",
    "                                   sEE, sIE, sEI, sII, D,\n",
    "                                   dE, dI, P, Q, tE, tI, \n",
    "                                      \n",
    "                                                                    aDWEE,aDWIE, aDWEI, aDWII,\n",
    "                                    bDWEE, bDWIE, bDWEI, bDWII,        \n",
    "                                      \n",
    "                                snE, snI, Graph_Kernel,\n",
    "                                \n",
    "                                   E_total=E_total,\n",
    "                                   \n",
    "                                   prediction=True, max_omega=Max_omega, delta_omega=Delta_omega,\n",
    "                                   \n",
    "                                   one_dim=False, syn=syn, gridsize=gridsize, h=h,\n",
    "                                      \n",
    "                                   eigvals=eigenvalues, eigvecs=eigenvectors,\n",
    "                                   \n",
    "                                   Visual=True, Save_Results=False, Filepath=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_full, TPS_full = Activity_Analysis(Ess, Iss, Delta_t,\n",
    "                                   aEE, aIE, aEI, aII,\n",
    "                                   sEE, sIE, sEI, sII, D,\n",
    "                                   dE, dI, P, Q, tE, tI, \n",
    "                                      \n",
    "                                                                    aDWEE,aDWIE, aDWEI, aDWII,\n",
    "                                    bDWEE, bDWIE, bDWEI, bDWII,        \n",
    "                                      \n",
    "                                snE, snI, Graph_Kernel,\n",
    "                                \n",
    "                                   E_total=E_total,\n",
    "                                   \n",
    "                                   prediction=True, max_omega=Max_omega, delta_omega=Delta_omega,\n",
    "                                   \n",
    "                                   one_dim=False, syn=syn, gridsize=gridsize, h=h,\n",
    "                                      \n",
    "                                   eigvals=eigenvalues, eigvecs=eigenvectors,\n",
    "                                   \n",
    "                                   Visual=True, Save_Results=False, Filepath=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/aqil/NFModel/nonlsim_fix_TPS.npy', TPS_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma\n",
    "def hrf(times):\n",
    "    \"\"\" Return values for HRF at given times \"\"\"\n",
    "    # Gamma pdf for the peak\n",
    "    peak_values = gamma.pdf(times, 6)\n",
    "    # Gamma pdf for the undershoot\n",
    "    undershoot_values = gamma.pdf(times, 12)\n",
    "    # Combine them\n",
    "    values = peak_values - 0.35 * undershoot_values\n",
    "    # Scale max to 0.6\n",
    "    return values / np.max(values)\n",
    "\n",
    "hrf_times = np.arange(0, 25, 0.0001)\n",
    "hrf_signal=100*hrf(hrf_times)\n",
    "print(hrf_signal.reshape(1,-1).shape)\n",
    "plt.figure()\n",
    "plt.plot(hrf_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not working?\n",
    "E_total_fMRI = sp.signal.fftconvolve(E_total-E_total.mean(1)[...,np.newaxis], hrf_signal.reshape(1,-1), mode='same', axes=(-1))[...,::10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#plt.plot(100*E_total[0])\n",
    "plt.plot(sp.signal.fftconvolve((E_total[0]-E_total[0].mean()), hrf_signal, mode='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC_nonlinear_sim = np.corrcoef(E_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC_nonlinear_sim_fmri = np.corrcoef(E_total_fMRI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('/home/aqil/NFModel/nonlsim_fc_fmri.npy', FC_nonlinear_sim_fmri)\n",
    "#E_total = np.load('/home/aqil/NFModel/nonlsim_act.npy')\n",
    "\n",
    "#np.save('/home/aqil/NFModel/nonlsim_act_fix_DW.npy',E_total)\n",
    "np.save('/home/aqil/NFModel/gauss_start_wc.npy',E_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_total = np.load('/home/aqil/NFModel/nonlsim_act_fix_DW.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(10,10))\n",
    "#plt.ylim(3700,1200)\n",
    "#plt.xlim(5500,7500)\n",
    "#plt.ylim(10000,9000)\n",
    "#plt.xlim(11000,12000)\n",
    "plt.imshow(FC_nonlinear_sim, vmin=0, vmax=0.075, cmap='inferno')\n",
    "\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################******** PROPAGATOR TESTS ********#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#propagator test 1\n",
    "#damped wave/telegrapher parameters\n",
    "#params for first working tests: a=0.3, b=0.001, c=0, Delta_t=1, h=1 (worked with 2-normalized eigenvalues)\n",
    "#make a smaller: wave travels faster\n",
    "a=aDWEI#1e-9#better_result['x'][17]\n",
    "#make b larger: more diffusion\n",
    "b=bDWEI#1e-4#better_result['x'][21]\n",
    "#nonzero c: switch from damped wave to telegrapher eqn\n",
    "c=0\n",
    "\n",
    "# aEE, aIE, aEI, aII,\n",
    "# sEE, sIE, sEI, sII, D,\n",
    "# dE, dI, P, Q, tE, tI,                                       \n",
    "# aDWEE,aDWIE, aDWEI, aDWII,\n",
    "# bDWEE, bDWIE, bDWEI, bDWII,  \n",
    "\n",
    "gridsize=1000\n",
    "syn=10\n",
    "h=0.003\n",
    "#u_0=0.3*sp.signal.gaussian(gridsize, 10)#np.zeros(gridsize)#(-0.1/499**2)*(np.arange(gridsize)-499)**2 + 0.1 \n",
    "u_0 =np.zeros(gridsize)+0.05\n",
    "Delta_t=100*0.5*sEI**2 #1e-7#1e-5#*better_result['x'][11]**2\n",
    "Time=Delta_t*10000\n",
    "\n",
    "u_0[250]=0.054\n",
    "print(np.sum(u_0))\n",
    "u_final=graph_propagator_test(u_0, Time, Delta_t, kernel_param=Delta_t, Graph_Kernel='Damped Wave', a=a, b=b, c=c, sigma_noise=0.0,\n",
    "                          one_dim=True, syn=syn, gridsize=gridsize,  h=h, eigvals=None, eigvecs=None,                         \n",
    "                          Visual=True, SaveActivity=False, Filepath=' ', NSim=0)\n",
    "print(np.sum(u_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#propagator test 2\n",
    "gridsize=1000\n",
    "syn=0\n",
    "h=1\n",
    "u_0=np.zeros(gridsize)#(-0.1/499**2)*(np.arange(gridsize)-499)**2 + 0.1 \n",
    "Delta_t=0.005\n",
    "Time=Delta_t\n",
    "u_0[499]=1000\n",
    "#u_0=np.ones(gridsize)\n",
    "print(np.sum(u_0))\n",
    "u_final=graph_propagator_test(u_0, Time, Delta_t, kernel_param=Delta_t, Graph_Kernel='Pyramid', sigma_noise=0,\n",
    "                          one_dim=True, syn=syn, gridsize=gridsize,  h=h, eigvals=None, eigvecs=None,                         \n",
    "                          Visual=True, SaveActivity=False, Filepath=' ', NSim=0)\n",
    "print(np.sum(u_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#proptest 3 cortical mesh convolutions\n",
    "\n",
    "u_0=np.zeros(len(eigenvalues))#np.zeros(gridsize)#(-0.1/499**2)*(np.arange(gridsize)-499)**2 + 0.1 \n",
    "u_0[6369]=50\n",
    "u_prop=graph_propagator_test(u_0, Time=50, Delta_t=50, kernel_param=50/1000000, Graph_Kernel='Gaussian', sigma_noise=0.0,\n",
    "                          one_dim=False, syn=0, gridsize=0,  h=0, eigvals=eigenvalues, eigvecs=eigenvectors,                         \n",
    "                          Visual=False, SaveActivity=False, Filepath=' ', NSim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#propagator test 4: cortical mesh\n",
    "##NOTE: THESE PARAMETERS WERE FOR THE EIGENVALUES OF THE LAPLACIAN IN MILLIMIETERS\n",
    "#damped wave/telegrapher parameters\n",
    "#params for first working tests: a=0.3, b=0.001, c=0, Delta_t=1\n",
    "#params for wave first figure: a=0.3 b=0.005 c=0 (*1000000) (faster wave: a=0.15 b=0.0025)\n",
    "#make a smaller: wave travels faster\n",
    "a=0.3\n",
    "#make b larger: more diffusion\n",
    "b=0.005\n",
    "#nonzero c: switch from damped wave to telegrapher eqn\n",
    "c=0\n",
    "\n",
    "#in metres it should be enough to do (also change initial gaussian kernel param)\n",
    "a*=1000000\n",
    "b*=1000000\n",
    "\n",
    "\n",
    "u_0=np.zeros(len(eigenvalues))#np.zeros(gridsize)#(-0.1/499**2)*(np.arange(gridsize)-499)**2 + 0.1 \n",
    "Delta_t=1\n",
    "Time=60\n",
    "u_0[6369]=50\n",
    "\n",
    "#gauss kernel parm 50/1000000\n",
    "\n",
    "\n",
    "u_1=graph_propagator_test(np.dot(eigenvectors.T,u_0), Time=2, Delta_t=1, kernel_param=50/1000000, \n",
    "                          Graph_Kernel='Gaussian', sigma_noise=0.0,\n",
    "                          one_dim=False, syn=0, gridsize=0,  h=0, eigvals=eigenvalues, GF_domain=True,                         \n",
    "                          Visual=False, SaveActivity=False, Filepath=' ', NSim=0)\n",
    "u_total=graph_propagator_test(u_1[:,1], Time, Delta_t, kernel_param=Delta_t, Graph_Kernel='Damped Wave', a=a, b=b, c=c, sigma_noise=0.0,\n",
    "                          one_dim=False, syn=0, gridsize=0,  h=0, eigvals=eigenvalues, GF_domain=True,                       \n",
    "                          Visual=False, SaveActivity=False, Filepath=' ', NSim=0)\n",
    "u_total=np.dot(eigenvectors,u_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#propagator test 5\n",
    "#damped wave/telegrapher parameters\n",
    "#params for first working tests: a=0.3, b=0.001, c=0, Delta_t=1, h=1 (worked with 2-normalized eigenvalues)\n",
    "#make a smaller: wave travels faster\n",
    "a=aDWEE#1e-9#better_result['x'][17]\n",
    "#make b larger: more diffusion\n",
    "b=bDWEE#1e-4#better_result['x'][21]\n",
    "#nonzero c: switch from damped wave to telegrapher eqn\n",
    "c=0\n",
    "\n",
    "# aEE, aIE, aEI, aII,\n",
    "# sEE, sIE, sEI, sII, D,\n",
    "# dE, dI, P, Q, tE, tI,                                       \n",
    "# aDWEE,aDWIE, aDWEI, aDWII,\n",
    "# bDWEE, bDWIE, bDWEI, bDWII,  \n",
    "\n",
    "u_0=np.zeros(len(eigenvalues))+0.05\n",
    "Delta_t=0.5*sEE**2 \n",
    "Time=Delta_t*100\n",
    "u_0[6369]=0.06\n",
    "# u_1=graph_propagator_test(np.dot(eigenvectors.T,u_0), Time=2, Delta_t=1, kernel_param=50/1000000, \n",
    "#                           Graph_Kernel='Gaussian', sigma_noise=0.0,\n",
    "#                           one_dim=False, syn=0, gridsize=0,  h=0, eigvals=eigenvalues, GF_domain=True,                         \n",
    "#                           Visual=False, SaveActivity=False, Filepath=' ', NSim=0)\n",
    "\n",
    "u_total=graph_propagator_test(np.dot(eigenvectors.T,u_0), Time, Delta_t, kernel_param=Delta_t, Graph_Kernel='Damped Wave', a=a, b=b,\n",
    "                              c=c,  sigma_noise=0.0,\n",
    "                          one_dim=False, syn=0, gridsize=0,  h=0, eigvals=eigenvalues, GF_domain=True,                       \n",
    "                          Visual=False, SaveActivity=False, Filepath=' ', NSim=0)\n",
    "u_total=np.dot(eigenvectors,u_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamp_conn_activity = np.dot(eigenvectors.T, np.load('/home/aqil/NFModel/Beta_E_total0.npy')[:,::7200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#propagator test 5 stochastic damped wave in fourier domain for quantitative spectrum calculation\n",
    "\n",
    "#make a smaller: wave travels faster\n",
    "#make b larger: more diffusion\n",
    "\n",
    "#nonzero c: switch from damped wave to telegrapher eqn\n",
    "c=0\n",
    "\n",
    "\n",
    "a=0.3*1000000\n",
    "b=0.05*1000000\n",
    "sigma_noise=0.0001\n",
    "\n",
    "\n",
    "beta_0=np.ones(len(eigenvalues))#np.zeros(gridsize)#(-0.1/499**2)*(np.arange(gridsize)-499)**2 + 0.1 \n",
    "Delta_t=1\n",
    "Time=200\n",
    "\n",
    "dw_beta_act=graph_propagator_test(np.dot(eigenvectors.T, beta_0), Time, Delta_t, kernel_param=Delta_t, Graph_Kernel='Damped Wave', a=a, b=b, c=c,\n",
    "                                 sigma_noise=sigma_noise,\n",
    "                                 one_dim=False, syn=0, gridsize=0,  h=0, GF_domain=True, eigvals=eigenvalues,                          \n",
    "                                 Visual=False, SaveActivity=False, Filepath=' ', NSim=0)\n",
    "\n",
    "\n",
    "#dw_PS_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dw_beta_act = np.load('G:\\Macbook Stuff\\Simulation Results\\Damped Wave Kernel Test t=1\\0# Sim Activity.h5')\n",
    "dw_PS = np.var(dw_beta_act, axis=1)\n",
    "dw_TPS = sp.signal.periodogram(dw_beta_act, fs=1/Delta_t, detrend='constant', scaling='density')\n",
    "f = plt.figure()\n",
    "plt.plot(dw_PS)\n",
    "f2 = plt.figure()\n",
    "plt.plot(dw_TPS[0]*(2*np.pi),np.sum(dw_TPS[1], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a=10000\n",
    "b=50000000\n",
    "sigma_noise=0.001\n",
    "\n",
    "lambdas, omegas = np.meshgrid(eigenvalues, dw_TPS[0][1:]*(2*np.pi))\n",
    "prediction = sigma_noise**2 / (b**2 * omegas**2 + (lambdas - a*omegas**2)**2)\n",
    "\n",
    "#f3 = plt.figure()\n",
    "#ax = f3.add_subplot(111)\n",
    "#pc = ax.pcolormesh(lambdas, omegas, prediction)\n",
    "#f3.colorbar(pc)\n",
    "\n",
    "f4 = plt.figure()\n",
    "plt.plot(dw_TPS[0][1]*np.sum(prediction, axis=0)/np.pi)\n",
    "f5 = plt.figure()\n",
    "plt.plot(dw_TPS[0][1:]*(2*np.pi), 2*np.sum(prediction, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "f = h5py.File('/home/aqil/NFModel/100307_Laplace.mat', 'r')\n",
    "CC = np.asarray(f['CC']['restInds'], dtype=int)\n",
    "indices = np.array([elem[0] for elem in CC])-1\n",
    "AllVet=np.asarray(f['vertices']['all'])\n",
    "AllVet=AllVet[:,indices]\n",
    "\n",
    "dist=np.sqrt(AllVet[0,:]**2 + AllVet[1,:]**2 + AllVet[2,:]**2)\n",
    "trace4 = go.Scatter3d(\n",
    "    x=AllVet[0,:],\n",
    "    y=AllVet[1,:],\n",
    "    z=AllVet[2,:],\n",
    "    #alphahull=50\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=dist,                # set color to an array/list of desired values\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=1,\n",
    "        #line=dict(color='rgba(0, 0, 0,0.5)',width=1,)\n",
    "        )\n",
    "    )\n",
    "data = [trace3]\n",
    "layout = go.Layout(\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('G:/Macbook Stuff/Simulation Results/Damped Wave Kernel Test t=1/0# Sim Activity b=0.005.h5', 'r') as file:\n",
    "    print(list(file.keys()))\n",
    "    DWave = np.asarray(file['Activity'], dtype=float)\n",
    "\n",
    "DWave[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#beta_u_total=np.load('G:/Macbook Stuff/Simulation Results/new realistic activity.npy')#np.dot(eigenvectors, dw_beta_act)\n",
    "#u_total=np.dot(eigenvectors,beta_u_total)\n",
    "#del beta_u_total\n",
    "#del eigenvectors\n",
    "#covariance = np.cov(u_total)\n",
    "#del u_total\n",
    "#FC=np.dot(np.diag(np.power(np.diag(covariance),-0.5)),np.dot(covariance,np.diag(np.power(np.diag(covariance),-0.5))))    \n",
    "#del covariance\n",
    "\n",
    "plt.close('all')\n",
    "fig=plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(FC, vmax=0.1, vmin=-0.1)\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "E_total = np.dot(eigenvectors,Beta_E_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "#init_notebook_mode(connected=True)\n",
    "offline.init_notebook_mode()\n",
    "\n",
    "#mesh (or full connectome) graph edges\n",
    "#trace1=Scatter3d(x=Xe,\n",
    "#               y=Ye,\n",
    "#               z=Ze,\n",
    "#               mode='lines',\n",
    "#              line=Line(color='rgba(0,0,0,1)', width=1),\n",
    "#             )\n",
    "\n",
    "#Mesh3d\n",
    "trace2=Mesh3d(x=Xn,\n",
    "               y=Yn,\n",
    "               z=Zn,\n",
    "              i=iN,\n",
    "              j=jN,\n",
    "              k=kN,\n",
    "              text=np.arange(len(Xn)),\n",
    "              #lighting used for NFModel plots, not for DWave\n",
    "             lighting = dict(ambient=1, diffuse=0.1, roughness = 0.9, specular=1.8, fresnel=0.01),\n",
    "              #colorlimits USE IF NEEDED (0.1 good for Dwave, 0.01 to show WMprop)(20 good for fmri demeaned)\n",
    "              cmin=-0.0005,#Ess-2*1e-7,#0.05,#,#20,#-10E-9,#-0.1,#-10E-9,#-0.1,\n",
    "              cmax=0.0005,#Ess+2*1e-7,#0.0501,#Ess+5*1e-7,#20, #10E-9#0.1#10E-9#0.1\n",
    "              #eigenvectors[:,1001]#\n",
    "              \n",
    "            \n",
    "              \n",
    "          #     mode='markers',\n",
    "          #  marker=dict(\n",
    "          #          size=5,\n",
    "          #          color=-AllVet[1,:],#np.sqrt(AllVet[2,:]**2+AllVet[0,:]**2+AllVet[1,:]**2),                # set color to an array/list of desired values\n",
    "                    colorscale='RdBu_r',   # choose a colorscale\n",
    "          #          opacity=0.8,\n",
    "          #          line=dict(color='rgba(0, 0, 0,0.5)',\n",
    "          #                     width=1,\n",
    "        #                     )\n",
    "        #                )\n",
    "                )\n",
    "\n",
    "\n",
    "###SET WHAT IS GONNA BE PLOTTED\n",
    "interval = 40\n",
    "start_time = 0\n",
    "max_time = 100 * interval\n",
    "\n",
    "#timecourse_demeaned = timecourse-timecourse.mean(1)[...,np.newaxis]\n",
    "#np.sqrt(3.85007284e+18)*resamp_conn_activity[:,i]\n",
    "#np.nan_to_num(sp.stats.zscore(timecourse, axis=1))[:,i]\n",
    "#np.nan_to_num(sp.stats.zscore(resamp_conn_activity, axis=1))[:,i]\n",
    "frames =[dict(data=[dict(type='mesh3d', \n",
    "                         #HERE IS WHAT DECIDES THE COLOR-TIMEPLOT\n",
    "                         intensity= E_total[:,i])],#u_total[:,i])],#eigenvectors[:,i]\n",
    "                  traces=[0],\n",
    "                  name='{}'.format(i)) for i in range(start_time,max_time,interval)] \n",
    "\n",
    "\n",
    "\n",
    "axis=dict(showbackground=False,\n",
    "          showline=False,\n",
    "          zeroline=False,\n",
    "          showgrid=False,\n",
    "          showticklabels=False,\n",
    "          title=''\n",
    "          )\n",
    "                 \n",
    "layout = Layout(\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0\n",
    "    ),\n",
    "    scene=dict(\n",
    "             xaxis=dict(axis),\n",
    "             yaxis=dict(axis),\n",
    "             zaxis=dict(axis),\n",
    "        camera = dict(\n",
    "    up=dict(x=0, y=0, z=1),\n",
    "    center=dict(x=0, y=0, z=0),\n",
    "            #good left occipital love view eye=dict(x=-1, y=-1.25, z=0.9). view from top eye=dict(x=0, y=0, z=1.8)\n",
    "    eye=dict(x=0, y=0, z=1.8)\n",
    ")),  \n",
    "    hovermode=False,     autosize=False,\n",
    "    width=1000,\n",
    "    height=1150\n",
    ")       \n",
    "data=[trace2]\n",
    "\n",
    "fig_frames = Figure(data=data, layout=layout, frames=frames)\n",
    "\n",
    "fig_frames['layout']['updatemenus'] = [\n",
    "    {\n",
    "        'buttons': [\n",
    "            {\n",
    "                'args': [None, {'frame': {'duration': 50, 'redraw': True},\n",
    "                         'fromcurrent': True, 'transition': {'duration': 10, 'easing': 'quadratic-in-out'}}],\n",
    "                'label': 'Play',\n",
    "                'method': 'animate'\n",
    "            },\n",
    "            {\n",
    "                'args': [[None], {'frame': {'duration': 0, 'redraw': True}, 'mode': 'immediate',\n",
    "                'transition': {'duration': 0}}], \n",
    "                'label': 'Pause',\n",
    "                'method': 'animate'\n",
    "            }\n",
    "        ],\n",
    "        'direction': 'left',\n",
    "        'pad': {'r': 10, 't': 87},\n",
    "        'showactive': True,\n",
    "        'type': 'buttons',\n",
    "        'x': 0.1,\n",
    "        'xanchor': 'right',\n",
    "        'y': 0,\n",
    "        'yanchor': 'top'\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "fig_frames['layout']['sliders'] = [{\n",
    "    'active': 0,\n",
    "    'yanchor': 'top',\n",
    "    'xanchor': 'left',\n",
    "    'currentvalue': {\n",
    "        'font': {'size': 20},\n",
    "        'prefix': 'time=',\n",
    "        'visible': True,\n",
    "        'xanchor': 'right'\n",
    "    },\n",
    "    'transition': {'duration': 10, 'easing': 'cubic-in-out'},\n",
    "    'pad': {'b': 10, 't': 5},\n",
    "    'len': 0.9,\n",
    "    'x': 0.1,\n",
    "    'y': 0,\n",
    "    'steps': [{\n",
    "    'method': 'animate',\n",
    "    'label': '{}'.format(i),\n",
    "   # 'value': '',\n",
    "    'args': [[i], {'frame': {'duration': 50, 'redraw': True},\n",
    "         'mode': 'immediate'}\n",
    "    ],\n",
    "} for i in range(start_time,max_time,interval)]\n",
    "}]\n",
    "\n",
    "\n",
    "\n",
    "#fig=Figure(data=data, layout=layout)\n",
    "\n",
    "offline.iplot(fig_frames, filename='Les-Miserables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('G:/Macbook Stuff/Downloads/Fibers.mat', 'r') as file:\n",
    "    print(list(file.keys()))\n",
    "    print(list(file['fgCC'].keys()))\n",
    "        \n",
    "    Fibers=[file[element][:] for element in file['fgCC']['fibers'][0]]\n",
    "\n",
    "fiber_edges=np.load('G:/Macbook Stuff/Downloads/NeuralFieldModelv2/fgCC_fiber_edges.npy')\n",
    "f = h5py.File('G:/Macbook Stuff/Downloads/NeuralFieldModelv2/100307_Laplace.mat', 'r')\n",
    "CC = np.asarray(f['CC']['restInds'], dtype=int)\n",
    "f.close()\n",
    "indices = np.array([elem[0] for elem in CC])-1\n",
    "EX=[]\n",
    "EY=[]\n",
    "EZ=[]\n",
    "colors=[]\n",
    "\n",
    "counter=0\n",
    "for i in range(0,len(Fibers),2):\n",
    "    if fiber_edges[i,0] in indices and fiber_edges[i,1] in indices and fiber_edges[i,0]!=fiber_edges[i,1]:\n",
    "        counter+=1\n",
    "        for j in range(Fibers[i].shape[0]-1):\n",
    "            EX+=[Fibers[i][j,0], Fibers[i][j+1,0], None]\n",
    "            EY+=[Fibers[i][j,1], Fibers[i][j+1,1], None]\n",
    "            EZ+=[Fibers[i][j,2], Fibers[i][j+1,2], None]\n",
    "\n",
    "counter    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_total.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_frames.write_image(\"G:/fig1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "#init_notebook_mode(connected=True)\n",
    "offline.init_notebook_mode()\n",
    "\n",
    "trace3=Scatter3d(x=EX,\n",
    "               y=EY,\n",
    "               z=EZ,\n",
    "               mode='lines',\n",
    "               line=Line(color=EX,#'rgba(100,100,100,0.9)',#colors\n",
    "                         #colorscale=[[0, 'rgb(0,0,255)'], [1, 'rgb(255,0,0)']],#'Rainbow',\n",
    "                         width=1),\n",
    "               )\n",
    "axis=dict(showbackground=False,\n",
    "          showline=False,\n",
    "          zeroline=False,\n",
    "          showgrid=False,\n",
    "          showticklabels=False,\n",
    "          title=''\n",
    "          )\n",
    "                 \n",
    "layout = Layout(\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0\n",
    "    ),\n",
    "    scene=dict(\n",
    "             xaxis=dict(axis),\n",
    "             yaxis=dict(axis),\n",
    "             zaxis=dict(axis),\n",
    "        ),\n",
    "    hovermode=False\n",
    ")       \n",
    "data=Data([trace3])\n",
    "fig=Figure(data=data, layout=layout)\n",
    "\n",
    "offline.iplot(fig, filename='Les-Miserables-2')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "169.219px",
    "left": "23.929px",
    "top": "184.048px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
